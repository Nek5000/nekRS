#!/bin/bash
set -e

: ${QUEUE:="prod"} # debug, debug-scaling, prod https://docs.alcf.anl.gov/running-jobs/job-and-queue-scheduling/

source $NEKRS_HOME/bin/nrsqsub_utils
setup $# 1

gpu_per_node=4
cores_per_numa=8
let nn=$nodes*$gpu_per_node
let ntasks=nn

backend=CUDA
NEKRS_GPU_MPI=1

chk_case $ntasks


striping_unit=16777216
max_striping_factor=128
set +e; let striping_factor=$nodes/2; set -e
if [ $striping_factor -gt $max_striping_factor ]; then
  striping_factor=$max_striping_factor
fi
if [ $striping_factor -lt 1 ]; then
  striping_factor=1
fi

MPICH_MPIIO_HINTS="*:striping_unit=${striping_unit}:striping_factor=${striping_factor}:romio_cb_write=enable:romio_ds_write=disable:romio_no_indep_rw=true"

# sbatch
SFILE=s.bin
echo "#!/bin/bash" > $SFILE
echo "#PBS -A $PROJ_ID" >>$SFILE
echo "#PBS -N $jobname" >>$SFILE
echo "#PBS -q $QUEUE" >>$SFILE
echo "#PBS -l walltime=${time}:00" >>$SFILE
echo "#PBS -l filesystems=home:eagle:grand" >>$SFILE
echo "#PBS -l select=$qnodes:system=polaris" >>$SFILE
echo "#PBS -l place=scatter" >>$SFILE
echo "#PBS -k doe" >>$SFILE #write directly to the destination, doe=direct, output, error
echo "#PBS -j eo" >>$SFILE  #oe=merge stdout/stderr to stdout


# job to “run” from your submission directory
echo "cd \$PBS_O_WORKDIR" >> $SFILE
echo "echo Jobid: \$PBS_JOBID" >>$SFILE
echo "echo Running on host \`hostname\`" >>$SFILE
echo "echo Running on nodes \`cat \$PBS_NODEFILE\`" >>$SFILE

echo "module use /soft/modulefiles" >> $SFILE
echo "module use /opt/cray/pe/lmod/modulefiles/mix_compilers" >> $SFILE
echo "module load libfabric" >> $SFILE
echo "module load PrgEnv-gnu" >> $SFILE
echo "module load nvhpc-mixed" >> $SFILE
echo "module load craype-x86-milan craype-accel-nvidia80" >> $SFILE
echo "module load spack-pe-base cmake" >> $SFILE
echo "module load visualization/ascent" >> $SFILE
echo "module list" >> $SFILE

# Ascent
echo "export NEKRS_ASCENT_INSTALL_DIR=\"/soft/visualization/ascent/develop/2024-05-03-8baa78c/ascent-develop\"" >> $SFILE

echo "nvidia-smi" >> $SFILE
echo "ulimit -s unlimited " >>$SFILE

echo "export NEKRS_HOME=$NEKRS_HOME" >>$SFILE
echo "export NEKRS_GPU_MPI=$NEKRS_GPU_MPI" >>$SFILE

echo "export MPICH_MPIIO_HINTS=$MPICH_MPIIO_HINTS" >>$SFILE
echo "export MPICH_MPIIO_STATS=1" >>$SFILE

echo "export NEKRS_CACHE_BCAST=$NEKRS_CACHE_BCAST" >>$SFILE
echo "export NEKRS_LOCAL_TMP_DIR=/local/scratch" >>$SFILE

echo "export MPICH_GPU_SUPPORT_ENABLED=1" >> $SFILE
echo "export MPICH_OFI_NIC_POLICY=NUMA" >> $SFILE

CMD=.lhelper
echo "#!/bin/bash" >$CMD
echo "gpu_id=\$((${gpu_per_node} - 1 - \${PMI_LOCAL_RANK} % ${gpu_per_node}))" >>$CMD
echo "export CUDA_VISIBLE_DEVICES=\$gpu_id" >>$CMD
echo "\$*" >>$CMD
chmod 755 $CMD

if [ $RUN_ONLY -eq 0 ]; then
  echo -e "\n# precompilation" >>$SFILE
  CMD_build="mpiexec -n $gpu_per_node -ppn $gpu_per_node -d $cores_per_numa --cpu-bind depth ./$CMD $bin --setup \${case_tmp} --backend ${backend} --device-id 0 $extra_args --build-only \$ntasks_tmp"
  add_build_CMD "$SFILE" "$CMD_build" "$ntasks"
fi

if [ $BUILD_ONLY -eq 0 ]; then
  link_neknek_logfile "$SFILE"
  echo -e "\n# actual run" >>$SFILE
  echo "mpiexec -n $ntasks -ppn $gpu_per_node -d $cores_per_numa --cpu-bind depth ./$CMD $bin --setup ${case} --backend ${backend} --device-id 0 $extra_args" >>$SFILE
fi
qsub -q $QUEUE $SFILE

# clean-up
#rm -rf $SFILE $ROMIO_HINTS .lhelper
