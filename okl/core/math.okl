@kernel void max(const dlong N,
                 @restrict const  dfloat *  x,
                 @restrict dfloat *  wxx){
  

  for(dlong b=0;b<(N+p_blockSize-1)/p_blockSize;++b;@outer(0)){
    
    @shared volatile dfloat s_wxx[p_blockSize];
    
    for(int t=0;t<p_blockSize;++t;@inner(0)){
      const dlong id = t + p_blockSize*b;
      s_wxx[t] = (id<N)?x[id]:0;
    }
    
    @barrier("local");
#if p_blockSize>512
    for(int t=0;t<p_blockSize;++t;@inner(0)) if(t<512) s_wxx[t] = (s_wxx[t]>s_wxx[t+512]) ? s_wxx[t]:s_wxx[t+512];
    @barrier("local");
#endif
#if p_blockSize>256
    for(int t=0;t<p_blockSize;++t;@inner(0)) if(t<256) s_wxx[t] = (s_wxx[t]>s_wxx[t+256]) ? s_wxx[t]:s_wxx[t+256];
    @barrier("local");
#endif

    for(int t=0;t<p_blockSize;++t;@inner(0)) if(t<128) s_wxx[t] = (s_wxx[t]>s_wxx[t+128]) ? s_wxx[t]:s_wxx[t+128];
    @barrier("local");

    for(int t=0;t<p_blockSize;++t;@inner(0)) if(t< 64) s_wxx[t] = (s_wxx[t]>s_wxx[t+64]) ? s_wxx[t]:s_wxx[t+64];
    @barrier("local");

    for(int t=0;t<p_blockSize;++t;@inner(0)) if(t< 32) s_wxx[t] = (s_wxx[t]>s_wxx[t+32]) ? s_wxx[t]:s_wxx[t+32];
    for(int t=0;t<p_blockSize;++t;@inner(0)) if(t< 16) s_wxx[t] = (s_wxx[t]>s_wxx[t+16]) ? s_wxx[t]:s_wxx[t+16];
    for(int t=0;t<p_blockSize;++t;@inner(0)) if(t<  8) s_wxx[t] = (s_wxx[t]>s_wxx[t+8]) ? s_wxx[t]:s_wxx[t+8];
    for(int t=0;t<p_blockSize;++t;@inner(0)) if(t<  4) s_wxx[t] = (s_wxx[t]>s_wxx[t+4]) ? s_wxx[t]:s_wxx[t+4];
    for(int t=0;t<p_blockSize;++t;@inner(0)) if(t<  2) s_wxx[t] = (s_wxx[t]>s_wxx[t+2]) ? s_wxx[t]:s_wxx[t+2];

    for(int t=0;t<p_blockSize;++t;@inner(0)) if(t<  1) wxx[b] = (s_wxx[0]>s_wxx[1]) ? s_wxx[0]:s_wxx[1];
  }
}

@kernel void scalarScaledAdd(const dlong N,
             const dfloat a,
             const dfloat b,
             @restrict const dfloat * X,
             @restrict dfloat * Y){

  for(dlong n=0;n<N;++n;@tile(256,@outer,@inner)){
    if(n<N){
      Y[n] = a + b*X[n]; 
    }
  }
}
