
// Currently Implemented for
@kernel void ellipticBlockAxHex3D_N1(const dlong Nelements,
                                     const dlong offset,
                                     const dlong loffset,
                                     @restrict const dfloat* ggeo,
                                     @restrict const dfloat* D,
                                     @restrict const dfloat*  S,
                                     @restrict const dfloat* lambda,
                                     @restrict const dfloat* q,
                                     @restrict dfloat* Aq)
{
  for(dlong e = 0; e < Nelements; ++e; @outer(0)) {
    @shared dfloat s_D[p_Nq][p_Nq];

    @shared dfloat s_U[p_Nq][p_Nq];
    @shared dfloat s_GUr[p_Nq][p_Nq];
    @shared dfloat s_GUs[p_Nq][p_Nq];

    @exclusive dfloat r_Ut;
    @exclusive dfloat r_U[p_Nq], r_AU[p_Nq];
    // array of threads
    for(int j = 0; j < p_Nq; ++j; @inner(1))
      for(int i = 0; i < p_Nq; ++i; @inner(0)) {
        //load D into local memory
        // s_D[i][j] = d \phi_i at node j
        s_D[j][i] = D[p_Nq * j + i]; // D is column major
        // load pencil of u into register
        const dlong base = i + j * p_Nq + e * p_Np;

        for(int k = 0; k < p_Nq; k++) {
          r_U[k] = q[base + k * p_Nq * p_Nq + 0 * offset];
          //zero out
          r_AU[k] = 0.f;
        }
      }

    // Layer by layer
#pragma unroll p_Nq
    for(int k = 0; k < p_Nq; k++) {
      @barrier("local");

      for(int j = 0; j < p_Nq; ++j; @inner(1)) {
        for(int i = 0; i < p_Nq; ++i; @inner(0)) {
          s_U[j][i] = r_U[k];
          r_Ut = 0;

#pragma unroll p_Nq
          for(int m = 0; m < p_Nq; m++) {
            dfloat Dkm = s_D[k][m];
            r_Ut += Dkm * r_U[m];
          }
        }
      }

      @barrier("local");

      for(int j = 0; j < p_Nq; ++j; @inner(1)) {
        for(int i = 0; i < p_Nq; ++i; @inner(0)) {
          dfloat Ur = 0.f, Us = 0.f;
#pragma unroll p_Nq
          for(int m = 0; m < p_Nq; m++) {
            // 8 shared, 12 FLOPS => 12TB/s*12/(8*8) => 2.25TF on V100
            dfloat Dim = s_D[i][m];
            dfloat Djm = s_D[j][m];

            Ur += Dim * s_U[j][m];
            Us += Djm * s_U[m][i];
          }

          const dlong gbase = e * p_Nggeo * p_Np + k * p_Nq * p_Nq + j * p_Nq + i;

          const dfloat G00 = ggeo[gbase + p_G00ID * p_Np];
          const dfloat G01 = ggeo[gbase + p_G01ID * p_Np];
          const dfloat G02 = ggeo[gbase + p_G02ID * p_Np];

          const dfloat G11 = ggeo[gbase + p_G11ID * p_Np];
          const dfloat G12 = ggeo[gbase + p_G12ID * p_Np];
          const dfloat G22 = ggeo[gbase + p_G22ID * p_Np];

          const dfloat GwJ = ggeo[gbase + p_GWJID * p_Np];

          s_GUr[j][i] = (G00 * Ur + G01 * Us + G02 * r_Ut);
          s_GUs[j][i] = (G01 * Ur + G11 * Us + G12 * r_Ut);
          r_Ut        = (G02 * Ur + G12 * Us + G22 * r_Ut);
          r_AU[k]    += GwJ * lambda[0 * loffset] * r_U[k];
        }
      }

      @barrier("local");

      for(int j = 0; j < p_Nq; ++j; @inner(1)) {
        for(int i = 0; i < p_Nq; ++i; @inner(0)) {
          dfloat AUtmp = 0;

#pragma unroll p_Nq
          for(int m = 0; m < p_Nq; m++) {
            AUtmp   += s_D[m][i] * s_GUr[j][m];
            AUtmp   += s_D[m][j] * s_GUs[m][i];
            r_AU[m] += s_D[k][m] * r_Ut;
          }
          r_AU[k] += AUtmp;
        }
      }
    }

    // write out

    for(int j = 0; j < p_Nq; ++j; @inner(1)) {
      for(int i = 0; i < p_Nq; ++i; @inner(0)) {
#pragma unroll p_Nq
        for(int k = 0; k < p_Nq; k++) {
          const dlong id = e * p_Np + k * p_Nq * p_Nq + j * p_Nq + i;
          Aq[id + 0 * offset] = r_AU[k];
        }
      }
    }
  }
}

// Currently Implemented for
@kernel void ellipticBlockAxHex3D_N2(const dlong Nelements,
                                     const dlong offset,
                                     const dlong loffset,
                                     @restrict const dfloat* ggeo,
                                     @restrict const dfloat* D,
                                     @restrict const dfloat*  S,
                                     @restrict const dfloat* lambda,
                                     @restrict const dfloat* q,
                                     @restrict dfloat* Aq)
{
  for(dlong e = 0; e < Nelements; ++e; @outer(0)) {
    @shared dfloat s_D[p_Nq][p_Nq];

    @shared dfloat s_U[p_Nq][p_Nq];
    @shared dfloat s_V[p_Nq][p_Nq];

    @shared dfloat s_GUr[p_Nq][p_Nq];
    @shared dfloat s_GUs[p_Nq][p_Nq];
    @shared dfloat s_GVr[p_Nq][p_Nq];
    @shared dfloat s_GVs[p_Nq][p_Nq];

    @exclusive dfloat r_Ut, r_Vt;

    // too much register ....(2*3*8 for N=7)
    @exclusive dfloat r_U[p_Nq], r_V[p_Nq];
    @exclusive dfloat r_AU[p_Nq], r_AV[p_Nq];

    // array of threads
    for(int j = 0; j < p_Nq; ++j; @inner(1))
      for(int i = 0; i < p_Nq; ++i; @inner(0)) {
        //load D into local memory
        // s_D[i][j] = d \phi_i at node j
        s_D[j][i] = D[p_Nq * j + i]; // D is column major

        // load pencil of u into register
        const dlong base = i + j * p_Nq + e * p_Np;

        for(int k = 0; k < p_Nq; k++) {
          //
          r_U[k] = q[base + k * p_Nq * p_Nq + 0 * offset];
          r_V[k] = q[base + k * p_Nq * p_Nq + 1 * offset];
          //
          r_AU[k] = 0.f;
          r_AV[k] = 0.f;
        }
      }

    // Layer by layer
#pragma unroll p_Nq
    for(int k = 0; k < p_Nq; k++) {
      @barrier("local");

      for(int j = 0; j < p_Nq; ++j; @inner(1)) {
        for(int i = 0; i < p_Nq; ++i; @inner(0)) {
          // share u(:,:,k)
          s_U[j][i] = r_U[k];
          s_V[j][i] = r_V[k];

          r_Ut = 0.f;
          r_Vt = 0.f;

#pragma unroll p_Nq
          for(int m = 0; m < p_Nq; m++) {
            // 1 shared, 6 flops => 12*6/(1*8) = 9 TFLOPSs > peak
            dfloat Dkm = s_D[k][m];
            r_Ut += Dkm * r_U[m];
            r_Vt += Dkm * r_V[m];
          }
        }
      }

      @barrier("local");

      for(int j = 0; j < p_Nq; ++j; @inner(1)) {
        for(int i = 0; i < p_Nq; ++i; @inner(0)) {
          dfloat Ur = 0.f, Us = 0.f;
          dfloat Vr = 0.f, Vs = 0.f;

#pragma unroll p_Nq
          for(int m = 0; m < p_Nq; m++) {
            // 8 shared, 12 FLOPS => 12TB/s*12/(8*8) => 2.25TF on V100
            dfloat Dim = s_D[i][m];
            dfloat Djm = s_D[j][m];

            Ur += Dim * s_U[j][m];
            Us += Djm * s_U[m][i];

            Vr += Dim * s_V[j][m];
            Vs += Djm * s_V[m][i];
          }

          const dlong gbase = e * p_Nggeo * p_Np + k * p_Nq * p_Nq + j * p_Nq + i;

          const dfloat G00 = ggeo[gbase + p_G00ID * p_Np];
          const dfloat G01 = ggeo[gbase + p_G01ID * p_Np];
          const dfloat G02 = ggeo[gbase + p_G02ID * p_Np];

          const dfloat G11 = ggeo[gbase + p_G11ID * p_Np];
          const dfloat G12 = ggeo[gbase + p_G12ID * p_Np];
          const dfloat G22 = ggeo[gbase + p_G22ID * p_Np];

          const dfloat GwJ = ggeo[gbase + p_GWJID * p_Np];

          s_GUr[j][i] = (G00 * Ur + G01 * Us + G02 * r_Ut);
          s_GVr[j][i] = (G00 * Vr + G01 * Vs + G02 * r_Vt);

          s_GUs[j][i] = (G01 * Ur + G11 * Us + G12 * r_Ut);
          s_GVs[j][i] = (G01 * Vr + G11 * Vs + G12 * r_Vt);

          r_Ut = (G02 * Ur + G12 * Us + G22 * r_Ut);
          r_Vt = (G02 * Vr + G12 * Vs + G22 * r_Vt);

          r_AU[k] += GwJ * lambda[0 * loffset] * r_U[k];
          r_AV[k] += GwJ * lambda[1 * loffset] * r_V[k];
        }
      }

      @barrier("local");

      for(int j = 0; j < p_Nq; ++j; @inner(1)) {
        for(int i = 0; i < p_Nq; ++i; @inner(0)) {
          dfloat AUtmp = 0, AVtmp = 0;

#pragma unroll p_Nq
          for(int m = 0; m < p_Nq; m++) {
            // 9 shared, 18 flops => 12TB/s*18/(9*8) = 3TFLOPS/s
            dfloat Dmi = s_D[m][i];
            dfloat Dmj = s_D[m][j];
            dfloat Dkm = s_D[k][m];

            AUtmp += Dmi * s_GUr[j][m];
            AUtmp += Dmj * s_GUs[m][i];

            AVtmp += Dmi * s_GVr[j][m];
            AVtmp += Dmj * s_GVs[m][i];

            r_AU[m] += Dkm * r_Ut;
            r_AV[m] += Dkm * r_Vt;
          }
          r_AU[k] += AUtmp;
          r_AV[k] += AVtmp;
        }
      }
    }

    for(int j = 0; j < p_Nq; ++j; @inner(1)) {
      for(int i = 0; i < p_Nq; ++i; @inner(0)) {
#pragma unroll p_Nq
        for(int k = 0; k < p_Nq; k++) {
          const dlong id = e * p_Np + k * p_Nq * p_Nq + j * p_Nq + i;
          Aq[id + 0 * offset] = r_AU[k];
          Aq[id + 1 * offset] = r_AV[k];
        }
      }
    }
  }
}

// Currently Implemented for
@kernel void ellipticBlockAxHex3D_N3(const dlong Nelements,
                                     const dlong offset,
                                     const dlong loffset,
                                     @restrict const dfloat* ggeo,
                                     @restrict const dfloat* D,
                                     @restrict const dfloat*  S,
                                     @restrict const dfloat* lambda,
                                     @restrict const dfloat* q,
                                     @restrict dfloat* Aq)
{
  for(dlong e = 0; e < Nelements; ++e; @outer(0)) {
    @shared dfloat s_D[p_Nq][p_Nq];

    @shared dfloat s_U[p_Nq][p_Nq];
    @shared dfloat s_V[p_Nq][p_Nq];
    @shared dfloat s_W[p_Nq][p_Nq];

    @shared dfloat s_GUr[p_Nq][p_Nq];
    @shared dfloat s_GUs[p_Nq][p_Nq];

    @shared dfloat s_GVr[p_Nq][p_Nq];
    @shared dfloat s_GVs[p_Nq][p_Nq];

    @shared dfloat s_GWr[p_Nq][p_Nq];
    @shared dfloat s_GWs[p_Nq][p_Nq];

    @exclusive dfloat r_Ut, r_Vt, r_Wt;

    // too much register ....(2*3*8 for N=7)
    @exclusive dfloat r_U[p_Nq], r_V[p_Nq],  r_W[p_Nq];
    @exclusive dfloat r_AU[p_Nq], r_AV[p_Nq], r_AW[p_Nq];

    // array of threads
    for(int j = 0; j < p_Nq; ++j; @inner(1))
      for(int i = 0; i < p_Nq; ++i; @inner(0)) {
        //load D into local memory
        // s_D[i][j] = d \phi_i at node j
        s_D[j][i] = D[p_Nq * j + i]; // D is column major

        // load pencil of u into register
        const dlong base = i + j * p_Nq + e * p_Np;

        for(int k = 0; k < p_Nq; k++) {
          //
          r_U[k] = q[base + k * p_Nq * p_Nq + 0 * offset];
          r_V[k] = q[base + k * p_Nq * p_Nq + 1 * offset];
          r_W[k] = q[base + k * p_Nq * p_Nq + 2 * offset];
          //
          r_AU[k] = 0.f;
          r_AV[k] = 0.f;
          r_AW[k] = 0.f;
        }
      }

    // Layer by layer
#pragma unroll p_Nq
    for(int k = 0; k < p_Nq; k++) {
      @barrier("local");

      for(int j = 0; j < p_Nq; ++j; @inner(1)) {
        for(int i = 0; i < p_Nq; ++i; @inner(0)) {
          // share u(:,:,k)
          s_U[j][i] = r_U[k];
          s_V[j][i] = r_V[k];
          s_W[j][i] = r_W[k];

          r_Ut = 0;
          r_Vt = 0;
          r_Wt = 0;

#pragma unroll p_Nq
          for(int m = 0; m < p_Nq; m++) {
            // 1 shared, 6 flops => 12*6/(1*8) = 9 TFLOPSs > peak
            dfloat Dkm = s_D[k][m];
            r_Ut += Dkm * r_U[m];
            r_Vt += Dkm * r_V[m];
            r_Wt += Dkm * r_W[m];
          }
        }
      }

      @barrier("local");

      for(int j = 0; j < p_Nq; ++j; @inner(1)) {
        for(int i = 0; i < p_Nq; ++i; @inner(0)) {
          dfloat Ur = 0.f, Us = 0.f;
          dfloat Vr = 0.f, Vs = 0.f;
          dfloat Wr = 0.f, Ws = 0.f;

#pragma unroll p_Nq
          for(int m = 0; m < p_Nq; m++) {
            // 8 shared, 12 FLOPS => 12TB/s*12/(8*8) => 2.25TF on V100
            dfloat Dim = s_D[i][m];
            dfloat Djm = s_D[j][m];

            Ur += Dim * s_U[j][m];
            Us += Djm * s_U[m][i];

            Vr += Dim * s_V[j][m];
            Vs += Djm * s_V[m][i];

            Wr += Dim * s_W[j][m];
            Ws += Djm * s_W[m][i];
          }

          const dlong gbase = e * p_Nggeo * p_Np + k * p_Nq * p_Nq + j * p_Nq + i;

          const dfloat G00 = ggeo[gbase + p_G00ID * p_Np];
          const dfloat G01 = ggeo[gbase + p_G01ID * p_Np];
          const dfloat G02 = ggeo[gbase + p_G02ID * p_Np];

          const dfloat G11 = ggeo[gbase + p_G11ID * p_Np];
          const dfloat G12 = ggeo[gbase + p_G12ID * p_Np];
          const dfloat G22 = ggeo[gbase + p_G22ID * p_Np];

          const dfloat GwJ = ggeo[gbase + p_GWJID * p_Np];

          s_GUr[j][i] = (G00 * Ur + G01 * Us + G02 * r_Ut);
          s_GVr[j][i] = (G00 * Vr + G01 * Vs + G02 * r_Vt);
          s_GWr[j][i] = (G00 * Wr + G01 * Ws + G02 * r_Wt);

          s_GUs[j][i] = (G01 * Ur + G11 * Us + G12 * r_Ut);
          s_GVs[j][i] = (G01 * Vr + G11 * Vs + G12 * r_Vt);
          s_GWs[j][i] = (G01 * Wr + G11 * Ws + G12 * r_Wt);

          r_Ut = (G02 * Ur + G12 * Us + G22 * r_Ut);
          r_Vt = (G02 * Vr + G12 * Vs + G22 * r_Vt);
          r_Wt = (G02 * Wr + G12 * Ws + G22 * r_Wt);

          r_AU[k] += GwJ * lambda[0 * loffset] * r_U[k];
          r_AV[k] += GwJ * lambda[1 * loffset] * r_V[k];
          r_AW[k] += GwJ * lambda[2 * loffset] * r_W[k];
        }
      }

      @barrier("local");

      for(int j = 0; j < p_Nq; ++j; @inner(1)) {
        for(int i = 0; i < p_Nq; ++i; @inner(0)) {
          dfloat AUtmp = 0, AVtmp = 0, AWtmp = 0;

#pragma unroll p_Nq
          for(int m = 0; m < p_Nq; m++) {
            // 9 shared, 18 flops => 12TB/s*18/(9*8) = 3TFLOPS/s
            dfloat Dmi = s_D[m][i];
            dfloat Dmj = s_D[m][j];
            dfloat Dkm = s_D[k][m];

            AUtmp += Dmi * s_GUr[j][m];
            AUtmp += Dmj * s_GUs[m][i];

            AVtmp += Dmi * s_GVr[j][m];
            AVtmp += Dmj * s_GVs[m][i];

            AWtmp += Dmi * s_GWr[j][m];
            AWtmp += Dmj * s_GWs[m][i];

            r_AU[m] += Dkm * r_Ut;
            r_AV[m] += Dkm * r_Vt;
            r_AW[m] += Dkm * r_Wt;
          }

          r_AU[k] += AUtmp;
          r_AV[k] += AVtmp;
          r_AW[k] += AWtmp;
        }
      }
    }

    // write out

    for(int j = 0; j < p_Nq; ++j; @inner(1)) {
      for(int i = 0; i < p_Nq; ++i; @inner(0)) {
#pragma unroll p_Nq
        for(int k = 0; k < p_Nq; k++) {
          const dlong id = e * p_Np + k * p_Nq * p_Nq + j * p_Nq + i;
          Aq[id + 0 * offset] = r_AU[k];
          Aq[id + 1 * offset] = r_AV[k];
          Aq[id + 2 * offset] = r_AW[k];
        }
      }
    }
  }
}

@kernel void ellipticBlockPartialAxHex3D_N1(const dlong Nelements,
                                            const dlong offset,
                                            const dlong loffset,
                                            @restrict const dlong* elementList,
                                            @restrict const dfloat* ggeo,
                                            @restrict const dfloat* D,
                                            @restrict const dfloat*  S,
                                            @restrict const dfloat* lambda,
                                            @restrict const dfloat* q,
                                            @restrict dfloat* Aq)
{
  for(dlong e = 0; e < Nelements; ++e; @outer(0)) {
    @shared dfloat s_D[p_Nq][p_Nq];

    @shared dfloat s_U[p_Nq][p_Nq];
    @shared dfloat s_GUr[p_Nq][p_Nq];
    @shared dfloat s_GUs[p_Nq][p_Nq];

    @exclusive dlong element;

    @exclusive dfloat r_Ut;
    @exclusive dfloat r_U[p_Nq], r_AU[p_Nq];
    // array of threads
    for(int j = 0; j < p_Nq; ++j; @inner(1))
      for(int i = 0; i < p_Nq; ++i; @inner(0)) {
        element = elementList[e];
        //load D into local memory
        // s_D[i][j] = d \phi_i at node j
        s_D[j][i] = D[p_Nq * j + i]; // D is column major
        // load pencil of u into register
        // const dlong base = i + j*p_Nq + element*p_Np;

        for(int k = 0; k < p_Nq; k++) {
          const dlong id = i + j * p_Nq + k * p_Nq * p_Nq + element * p_Np;
          r_U[k] = q[id + 0 * offset];
          //zero out
          r_AU[k] = 0.f;
        }
      }

    // Layer by layer
#pragma unroll p_Nq
    for(int k = 0; k < p_Nq; k++) {
      @barrier("local");

      for(int j = 0; j < p_Nq; ++j; @inner(1)) {
        for(int i = 0; i < p_Nq; ++i; @inner(0)) {
          s_U[j][i] = r_U[k];
          r_Ut = 0;

#pragma unroll p_Nq
          for(int m = 0; m < p_Nq; m++) {
            dfloat Dkm = s_D[k][m];
            r_Ut += Dkm * r_U[m];
          }
        }
      }

      @barrier("local");

      for(int j = 0; j < p_Nq; ++j; @inner(1)) {
        for(int i = 0; i < p_Nq; ++i; @inner(0)) {
          dfloat Ur = 0.f, Us = 0.f;
#pragma unroll p_Nq
          for(int m = 0; m < p_Nq; m++) {
            // 8 shared, 12 FLOPS => 12TB/s*12/(8*8) => 2.25TF on V100
            dfloat Dim = s_D[i][m];
            dfloat Djm = s_D[j][m];

            Ur += Dim * s_U[j][m];
            Us += Djm * s_U[m][i];
          }

          const dlong gbase = element * p_Nggeo * p_Np + k * p_Nq * p_Nq + j * p_Nq + i;

          const dfloat G00 = ggeo[gbase + p_G00ID * p_Np];
          const dfloat G01 = ggeo[gbase + p_G01ID * p_Np];
          const dfloat G02 = ggeo[gbase + p_G02ID * p_Np];

          const dfloat G11 = ggeo[gbase + p_G11ID * p_Np];
          const dfloat G12 = ggeo[gbase + p_G12ID * p_Np];
          const dfloat G22 = ggeo[gbase + p_G22ID * p_Np];

          const dfloat GwJ = ggeo[gbase + p_GWJID * p_Np];

          s_GUr[j][i] = (G00 * Ur + G01 * Us + G02 * r_Ut);
          s_GUs[j][i] = (G01 * Ur + G11 * Us + G12 * r_Ut);
          r_Ut        = (G02 * Ur + G12 * Us + G22 * r_Ut);
          r_AU[k]    += GwJ * lambda[0 * loffset] * r_U[k];
        }
      }

      @barrier("local");

      for(int j = 0; j < p_Nq; ++j; @inner(1)) {
        for(int i = 0; i < p_Nq; ++i; @inner(0)) {
          dfloat AUtmp = 0;

#pragma unroll p_Nq
          for(int m = 0; m < p_Nq; m++) {
            AUtmp   += s_D[m][i] * s_GUr[j][m];
            AUtmp   += s_D[m][j] * s_GUs[m][i];
            r_AU[m] += s_D[k][m] * r_Ut;
          }
          r_AU[k] += AUtmp;
        }
      }
    }

    // write out

    for(int j = 0; j < p_Nq; ++j; @inner(1)) {
      for(int i = 0; i < p_Nq; ++i; @inner(0)) {
#pragma unroll p_Nq
        for(int k = 0; k < p_Nq; k++) {
          const dlong id = element * p_Np + k * p_Nq * p_Nq + j * p_Nq + i;
          Aq[id + 0 * offset] = r_AU[k];
          // Aq[id+0*offset] = id;
        }
      }
    }
  }
}

// Currently Implemented for
@kernel void ellipticBlockPartialAxHex3D_N2(const dlong Nelements,
                                            const dlong offset,
                                            const dlong loffset,
                                            @restrict const dlong* elementList,
                                            @restrict const dfloat* ggeo,
                                            @restrict const dfloat* D,
                                            @restrict const dfloat*  S,
                                            @restrict const dfloat* lambda,
                                            @restrict const dfloat* q,
                                            @restrict dfloat* Aq)
{
  for(dlong e = 0; e < Nelements; ++e; @outer(0)) {
    @shared dfloat s_D[p_Nq][p_Nq];

    @shared dfloat s_U[p_Nq][p_Nq];
    @shared dfloat s_V[p_Nq][p_Nq];

    @shared dfloat s_GUr[p_Nq][p_Nq];
    @shared dfloat s_GUs[p_Nq][p_Nq];
    @shared dfloat s_GVr[p_Nq][p_Nq];
    @shared dfloat s_GVs[p_Nq][p_Nq];

    @exclusive dlong element;

    @exclusive dfloat r_Ut, r_Vt;

    // too much register ....(2*3*8 for N=7)
    @exclusive dfloat r_U[p_Nq], r_V[p_Nq];
    @exclusive dfloat r_AU[p_Nq], r_AV[p_Nq];

    // array of threads
    for(int j = 0; j < p_Nq; ++j; @inner(1))
      for(int i = 0; i < p_Nq; ++i; @inner(0)) {
        element = elementList[e];
        //load D into local memory
        // s_D[i][j] = d \phi_i at node j
        s_D[j][i] = D[p_Nq * j + i]; // D is column major

        for(int k = 0; k < p_Nq; k++) {
          const dlong id = i + j * p_Nq + k * p_Nq * p_Nq + element * p_Np;
          //
          r_U[k] = q[id + 0 * offset];
          r_V[k] = q[id + 1 * offset];
          //
          r_AU[k] = 0.f;
          r_AV[k] = 0.f;
        }
      }

    // Layer by layer
#pragma unroll p_Nq
    for(int k = 0; k < p_Nq; k++) {
      @barrier("local");

      for(int j = 0; j < p_Nq; ++j; @inner(1)) {
        for(int i = 0; i < p_Nq; ++i; @inner(0)) {
          // share u(:,:,k)
          s_U[j][i] = r_U[k];
          s_V[j][i] = r_V[k];

          r_Ut = 0.f;
          r_Vt = 0.f;

#pragma unroll p_Nq
          for(int m = 0; m < p_Nq; m++) {
            // 1 shared, 6 flops => 12*6/(1*8) = 9 TFLOPSs > peak
            dfloat Dkm = s_D[k][m];
            r_Ut += Dkm * r_U[m];
            r_Vt += Dkm * r_V[m];
          }
        }
      }

      @barrier("local");

      for(int j = 0; j < p_Nq; ++j; @inner(1)) {
        for(int i = 0; i < p_Nq; ++i; @inner(0)) {
          dfloat Ur = 0.f, Us = 0.f;
          dfloat Vr = 0.f, Vs = 0.f;

#pragma unroll p_Nq
          for(int m = 0; m < p_Nq; m++) {
            // 8 shared, 12 FLOPS => 12TB/s*12/(8*8) => 2.25TF on V100
            dfloat Dim = s_D[i][m];
            dfloat Djm = s_D[j][m];

            Ur += Dim * s_U[j][m];
            Us += Djm * s_U[m][i];

            Vr += Dim * s_V[j][m];
            Vs += Djm * s_V[m][i];
          }

          const dlong gbase = element * p_Nggeo * p_Np + k * p_Nq * p_Nq + j * p_Nq + i;

          const dfloat G00 = ggeo[gbase + p_G00ID * p_Np];
          const dfloat G01 = ggeo[gbase + p_G01ID * p_Np];
          const dfloat G02 = ggeo[gbase + p_G02ID * p_Np];

          const dfloat G11 = ggeo[gbase + p_G11ID * p_Np];
          const dfloat G12 = ggeo[gbase + p_G12ID * p_Np];
          const dfloat G22 = ggeo[gbase + p_G22ID * p_Np];

          const dfloat GwJ = ggeo[gbase + p_GWJID * p_Np];

          s_GUr[j][i] = (G00 * Ur + G01 * Us + G02 * r_Ut);
          s_GVr[j][i] = (G00 * Vr + G01 * Vs + G02 * r_Vt);

          s_GUs[j][i] = (G01 * Ur + G11 * Us + G12 * r_Ut);
          s_GVs[j][i] = (G01 * Vr + G11 * Vs + G12 * r_Vt);

          r_Ut        = (G02 * Ur + G12 * Us + G22 * r_Ut);
          r_Vt        = (G02 * Vr + G12 * Vs + G22 * r_Vt);

          r_AU[k] += GwJ * lambda[0 * loffset] * r_U[k];
          r_AV[k] += GwJ * lambda[1 * loffset] * r_V[k];
        }
      }

      @barrier("local");

      for(int j = 0; j < p_Nq; ++j; @inner(1)) {
        for(int i = 0; i < p_Nq; ++i; @inner(0)) {
          dfloat AUtmp = 0, AVtmp = 0;
#pragma unroll p_Nq
          for(int m = 0; m < p_Nq; m++) {
            // 9 shared, 18 flops => 12TB/s*18/(9*8) = 3TFLOPS/s
            dfloat Dmi = s_D[m][i];
            dfloat Dmj = s_D[m][j];
            dfloat Dkm = s_D[k][m];

            AUtmp += Dmi * s_GUr[j][m];
            AUtmp += Dmj * s_GUs[m][i];
            //
            AVtmp += Dmi * s_GVr[j][m];
            AVtmp += Dmj * s_GVs[m][i];
            //
            r_AU[m] += Dkm * r_Ut;
            r_AV[m] += Dkm * r_Vt;
          }
          r_AU[k] += AUtmp;
          r_AV[k] += AVtmp;
        }
      }
    }

    for(int j = 0; j < p_Nq; ++j; @inner(1)) {
      for(int i = 0; i < p_Nq; ++i; @inner(0)) {
#pragma unroll p_Nq
        for(int k = 0; k < p_Nq; k++) {
          const dlong id = element * p_Np + k * p_Nq * p_Nq + j * p_Nq + i;
          const dfloat value = r_AU[k];
          Aq[id + 0 * offset] = r_AU[k];
          Aq[id + 1 * offset] = r_AV[k];
        }
      }
    }
  }
}

// Currently Implemented for
@kernel void ellipticBlockPartialAxHex3D_N3(const dlong Nelements,
                                            const dlong offset,
                                            const dlong loffset,
                                            @restrict const dlong* elementList,
                                            @restrict const dfloat* ggeo,
                                            @restrict const dfloat* D,
                                            @restrict const dfloat*  S,
                                            @restrict const dfloat* lambda,
                                            @restrict const dfloat* q,
                                            @restrict dfloat* Aq)
{
  for(dlong e = 0; e < Nelements; ++e; @outer(0)) {
    @shared dfloat s_D[p_Nq][p_Nq];

    @shared dfloat s_U[p_Nq][p_Nq];
    @shared dfloat s_V[p_Nq][p_Nq];
    @shared dfloat s_W[p_Nq][p_Nq];

    @shared dfloat s_GUr[p_Nq][p_Nq];
    @shared dfloat s_GUs[p_Nq][p_Nq];

    @shared dfloat s_GVr[p_Nq][p_Nq];
    @shared dfloat s_GVs[p_Nq][p_Nq];

    @shared dfloat s_GWr[p_Nq][p_Nq];
    @shared dfloat s_GWs[p_Nq][p_Nq];

    @exclusive dfloat r_Ut, r_Vt, r_Wt;

    @exclusive dlong element;
    // too much register ....(2*3*8 for N=7)
    @exclusive dfloat r_U[p_Nq], r_V[p_Nq],  r_W[p_Nq];
    @exclusive dfloat r_AU[p_Nq], r_AV[p_Nq], r_AW[p_Nq];

    // array of threads
    for(int j = 0; j < p_Nq; ++j; @inner(1))
      for(int i = 0; i < p_Nq; ++i; @inner(0)) {
        element = elementList[e];
        //load D into local memory
        // s_D[i][j] = d \phi_i at node j
        s_D[j][i] = D[p_Nq * j + i]; // D is column major

        // load pencil of u into register
        const dlong base = i + j * p_Nq + element * p_Np;

        for(int k = 0; k < p_Nq; k++) {
          //
          r_U[k] = q[base + k * p_Nq * p_Nq + 0 * offset];
          r_V[k] = q[base + k * p_Nq * p_Nq + 1 * offset];
          r_W[k] = q[base + k * p_Nq * p_Nq + 2 * offset];
          //
          r_AU[k] = 0.f;
          r_AV[k] = 0.f;
          r_AW[k] = 0.f;
        }
      }

    // Layer by layer
#pragma unroll p_Nq
    for(int k = 0; k < p_Nq; k++) {
      @barrier("local");

      for(int j = 0; j < p_Nq; ++j; @inner(1)) {
        for(int i = 0; i < p_Nq; ++i; @inner(0)) {
          // share u(:,:,k)
          s_U[j][i] = r_U[k];
          s_V[j][i] = r_V[k];
          s_W[j][i] = r_W[k];

          r_Ut = 0;
          r_Vt = 0;
          r_Wt = 0;

#pragma unroll p_Nq
          for(int m = 0; m < p_Nq; m++) {
            // 1 shared, 6 flops => 12*6/(1*8) = 9 TFLOPSs > peak
            dfloat Dkm = s_D[k][m];
            r_Ut += Dkm * r_U[m];
            r_Vt += Dkm * r_V[m];
            r_Wt += Dkm * r_W[m];
          }
        }
      }

      @barrier("local");

      for(int j = 0; j < p_Nq; ++j; @inner(1)) {
        for(int i = 0; i < p_Nq; ++i; @inner(0)) {
          dfloat Ur = 0.f, Us = 0.f;
          dfloat Vr = 0.f, Vs = 0.f;
          dfloat Wr = 0.f, Ws = 0.f;

#pragma unroll p_Nq
          for(int m = 0; m < p_Nq; m++) {
            // 8 shared, 12 FLOPS => 12TB/s*12/(8*8) => 2.25TF on V100
            dfloat Dim = s_D[i][m];
            dfloat Djm = s_D[j][m];

            Ur += Dim * s_U[j][m];
            Us += Djm * s_U[m][i];

            Vr += Dim * s_V[j][m];
            Vs += Djm * s_V[m][i];

            Wr += Dim * s_W[j][m];
            Ws += Djm * s_W[m][i];
          }

          const dlong gbase = element * p_Nggeo * p_Np + k * p_Nq * p_Nq + j * p_Nq + i;

          const dfloat G00 = ggeo[gbase + p_G00ID * p_Np];
          const dfloat G01 = ggeo[gbase + p_G01ID * p_Np];
          const dfloat G02 = ggeo[gbase + p_G02ID * p_Np];

          const dfloat G11 = ggeo[gbase + p_G11ID * p_Np];
          const dfloat G12 = ggeo[gbase + p_G12ID * p_Np];
          const dfloat G22 = ggeo[gbase + p_G22ID * p_Np];

          const dfloat GwJ = ggeo[gbase + p_GWJID * p_Np];

          s_GUr[j][i] = (G00 * Ur + G01 * Us + G02 * r_Ut);
          s_GVr[j][i] = (G00 * Vr + G01 * Vs + G02 * r_Vt);
          s_GWr[j][i] = (G00 * Wr + G01 * Ws + G02 * r_Wt);

          s_GUs[j][i] = (G01 * Ur + G11 * Us + G12 * r_Ut);
          s_GVs[j][i] = (G01 * Vr + G11 * Vs + G12 * r_Vt);
          s_GWs[j][i] = (G01 * Wr + G11 * Ws + G12 * r_Wt);

          r_Ut = (G02 * Ur + G12 * Us + G22 * r_Ut);
          r_Vt = (G02 * Vr + G12 * Vs + G22 * r_Vt);
          r_Wt = (G02 * Wr + G12 * Ws + G22 * r_Wt);

          r_AU[k] += GwJ * lambda[0 * loffset] * r_U[k];
          r_AV[k] += GwJ * lambda[1 * loffset] * r_V[k];
          r_AW[k] += GwJ * lambda[2 * loffset] * r_W[k];
        }
      }

      @barrier("local");

      for(int j = 0; j < p_Nq; ++j; @inner(1)) {
        for(int i = 0; i < p_Nq; ++i; @inner(0)) {
          dfloat AUtmp = 0, AVtmp = 0, AWtmp = 0;

#pragma unroll p_Nq
          for(int m = 0; m < p_Nq; m++) {
            // 9 shared, 18 flops => 12TB/s*18/(9*8) = 3TFLOPS/s
            dfloat Dmi = s_D[m][i];
            dfloat Dmj = s_D[m][j];
            dfloat Dkm = s_D[k][m];

            AUtmp += Dmi * s_GUr[j][m];
            AUtmp += Dmj * s_GUs[m][i];

            AVtmp += Dmi * s_GVr[j][m];
            AVtmp += Dmj * s_GVs[m][i];

            AWtmp += Dmi * s_GWr[j][m];
            AWtmp += Dmj * s_GWs[m][i];

            r_AU[m] += Dkm * r_Ut;
            r_AV[m] += Dkm * r_Vt;
            r_AW[m] += Dkm * r_Wt;
          }

          r_AU[k] += AUtmp;
          r_AV[k] += AVtmp;
          r_AW[k] += AWtmp;
        }
      }
    }

    // write out

    for(int j = 0; j < p_Nq; ++j; @inner(1)) {
      for(int i = 0; i < p_Nq; ++i; @inner(0)) {
#pragma unroll p_Nq
        for(int k = 0; k < p_Nq; k++) {
          const dlong id = element * p_Np + k * p_Nq * p_Nq + j * p_Nq + i;
          Aq[id + 0 * offset] = r_AU[k];
          Aq[id + 1 * offset] = r_AV[k];
          Aq[id + 2 * offset] = r_AW[k];
        }
      }
    }
  }
}

//
@kernel void ellipticBlockAxVarHex3D_N1(const dlong Nelements,
                                        const dlong offset,
                                        const dlong loffset,
                                        @restrict const dlong* elementList,
                                        @restrict const dfloat* ggeo,
                                        @restrict const dfloat* D,
                                        @restrict const dfloat*  S,
                                        @restrict const dfloat* lambda,
                                        @restrict const dfloat* q,
                                        @restrict dfloat* Aq)
{
  for(dlong e = 0; e < Nelements; ++e; @outer(0)) {
    @shared dfloat s_D[p_Nq][p_Nq];

    @shared dfloat s_U[p_Nq][p_Nq];
    @shared dfloat s_GUr[p_Nq][p_Nq];
    @shared dfloat s_GUs[p_Nq][p_Nq];

    @exclusive dfloat r_Ut;
    @exclusive dfloat r_U[p_Nq], r_AU[p_Nq];
    // array of threads
    for(int j = 0; j < p_Nq; ++j; @inner(1))
      for(int i = 0; i < p_Nq; ++i; @inner(0)) {
        //load D into local memory
        // s_D[i][j] = d \phi_i at node j
        s_D[j][i] = D[p_Nq * j + i]; // D is column major
        // load pencil of u into register
        const dlong base = i + j * p_Nq + e * p_Np;

        for(int k = 0; k < p_Nq; k++) {
          r_U[k] = q[base + k * p_Nq * p_Nq + 0 * offset];
          //zero out
          r_AU[k] = 0.f;
        }
      }

    // Layer by layer
#pragma unroll p_Nq
    for(int k = 0; k < p_Nq; k++) {
      @barrier("local");

      for(int j = 0; j < p_Nq; ++j; @inner(1)) {
        for(int i = 0; i < p_Nq; ++i; @inner(0)) {
          s_U[j][i] = r_U[k];
          r_Ut = 0;

#pragma unroll p_Nq
          for(int m = 0; m < p_Nq; m++) {
            dfloat Dkm = s_D[k][m];
            r_Ut += Dkm * r_U[m];
          }
        }
      }

      @barrier("local");

      for(int j = 0; j < p_Nq; ++j; @inner(1)) {
        for(int i = 0; i < p_Nq; ++i; @inner(0)) {
          dfloat Ur = 0.f, Us = 0.f;
#pragma unroll p_Nq
          for(int m = 0; m < p_Nq; m++) {
            // 8 shared, 12 FLOPS => 12TB/s*12/(8*8) => 2.25TF on V100
            dfloat Dim = s_D[i][m];
            dfloat Djm = s_D[j][m];

            Ur += Dim * s_U[j][m];
            Us += Djm * s_U[m][i];
          }

          const dlong id = e * p_Np + k * p_Nq * p_Nq + j * p_Nq + i;
          const dfloat u_lam0 = lambda[id + 0 * offset];
          const dfloat u_lam1 = lambda[id + 1 * offset];

          const dlong gbase = e * p_Nggeo * p_Np + k * p_Nq * p_Nq + j * p_Nq + i;

          const dfloat G00 = ggeo[gbase + p_G00ID * p_Np];
          const dfloat G01 = ggeo[gbase + p_G01ID * p_Np];
          const dfloat G02 = ggeo[gbase + p_G02ID * p_Np];

          const dfloat G11 = ggeo[gbase + p_G11ID * p_Np];
          const dfloat G12 = ggeo[gbase + p_G12ID * p_Np];
          const dfloat G22 = ggeo[gbase + p_G22ID * p_Np];

          const dfloat GwJ = ggeo[gbase + p_GWJID * p_Np];

          s_GUr[j][i] = u_lam0 * (G00 * Ur + G01 * Us + G02 * r_Ut);
          s_GUs[j][i] = u_lam0 * (G01 * Ur + G11 * Us + G12 * r_Ut);
          r_Ut        = u_lam0 * (G02 * Ur + G12 * Us + G22 * r_Ut);
          r_AU[k]    += GwJ * u_lam1 * r_U[k];
        }
      }

      @barrier("local");

      for(int j = 0; j < p_Nq; ++j; @inner(1)) {
        for(int i = 0; i < p_Nq; ++i; @inner(0)) {
          dfloat AUtmp = 0;

#pragma unroll p_Nq
          for(int m = 0; m < p_Nq; m++) {
            AUtmp   += s_D[m][i] * s_GUr[j][m];
            AUtmp   += s_D[m][j] * s_GUs[m][i];
            r_AU[m] += s_D[k][m] * r_Ut;
          }
          r_AU[k] += AUtmp;
        }
      }
    }

    // write out

    for(int j = 0; j < p_Nq; ++j; @inner(1)) {
      for(int i = 0; i < p_Nq; ++i; @inner(0)) {
#pragma unroll p_Nq
        for(int k = 0; k < p_Nq; k++) {
          const dlong id = e * p_Np + k * p_Nq * p_Nq + j * p_Nq + i;
          Aq[id + 0 * offset] = r_AU[k];
        }
      }
    }
  }
}

// Currently Implemented for
@kernel void ellipticBlockAxVarHex3D_N2(const dlong Nelements,
                                        const dlong offset,
                                        const dlong loffset,
                                        @restrict const dlong* elementList,
                                        @restrict const dfloat* ggeo,
                                        @restrict const dfloat* D,
                                        @restrict const dfloat*  S,
                                        @restrict const dfloat* lambda,
                                        @restrict const dfloat* q,
                                        @restrict dfloat* Aq)
{
  for(dlong e = 0; e < Nelements; ++e; @outer(0)) {
    @shared dfloat s_D[p_Nq][p_Nq];

    @shared dfloat s_U[p_Nq][p_Nq];
    @shared dfloat s_V[p_Nq][p_Nq];
    @shared dfloat s_W[p_Nq][p_Nq];

    @shared dfloat s_GUr[p_Nq][p_Nq];
    @shared dfloat s_GUs[p_Nq][p_Nq];
    @shared dfloat s_GVr[p_Nq][p_Nq];
    @shared dfloat s_GVs[p_Nq][p_Nq];

    @exclusive dfloat r_Ut, r_Vt, r_Wt;

    // too much register ....(2*3*8 for N=7)
    @exclusive dfloat r_U[p_Nq], r_V[p_Nq];
    @exclusive dfloat r_AU[p_Nq], r_AV[p_Nq];

    // array of threads
    for(int j = 0; j < p_Nq; ++j; @inner(1))
      for(int i = 0; i < p_Nq; ++i; @inner(0)) {
        //load D into local memory
        // s_D[i][j] = d \phi_i at node j
        s_D[j][i] = D[p_Nq * j + i]; // D is column major

        // load pencil of u into register
        const dlong base = i + j * p_Nq + e * p_Np;

        for(int k = 0; k < p_Nq; k++) {
          //
          r_U[k] = q[base + k * p_Nq * p_Nq + 0 * offset];
          r_V[k] = q[base + k * p_Nq * p_Nq + 1 * offset];
          //
          r_AU[k] = 0.f;
          r_AV[k] = 0.f;
        }
      }

    // Layer by layer
#pragma unroll p_Nq
    for(int k = 0; k < p_Nq; k++) {
      @barrier("local");

      for(int j = 0; j < p_Nq; ++j; @inner(1)) {
        for(int i = 0; i < p_Nq; ++i; @inner(0)) {
          // share u(:,:,k)
          s_U[j][i] = r_U[k];
          s_V[j][i] = r_V[k];

          r_Ut = 0;
          r_Vt = 0;

#pragma unroll p_Nq
          for(int m = 0; m < p_Nq; m++) {
            // 1 shared, 6 flops => 12*6/(1*8) = 9 TFLOPSs > peak
            dfloat Dkm = s_D[k][m];
            r_Ut += Dkm * r_U[m];
            r_Vt += Dkm * r_V[m];
          }
        }
      }

      @barrier("local");

      for(int j = 0; j < p_Nq; ++j; @inner(1)) {
        for(int i = 0; i < p_Nq; ++i; @inner(0)) {
          dfloat Ur = 0.f, Us = 0.f;
          dfloat Vr = 0.f, Vs = 0.f;

#pragma unroll p_Nq
          for(int m = 0; m < p_Nq; m++) {
            // 8 shared, 12 FLOPS => 12TB/s*12/(8*8) => 2.25TF on V100
            dfloat Dim = s_D[i][m];
            dfloat Djm = s_D[j][m];

            Ur += Dim * s_U[j][m];
            Us += Djm * s_U[m][i];

            Vr += Dim * s_V[j][m];
            Vs += Djm * s_V[m][i];
          }

          const dlong id = e * p_Np + k * p_Nq * p_Nq + j * p_Nq + i;
          const dfloat u_lam0 = lambda[id + 0 * offset + 0 * loffset];
          const dfloat u_lam1 = lambda[id + 1 * offset + 0 * loffset];

          const dfloat v_lam0 = lambda[id + 0 * offset + 1 * loffset];
          const dfloat v_lam1 = lambda[id + 1 * offset + 1 * loffset];

          const dlong gbase = e * p_Nggeo * p_Np + k * p_Nq * p_Nq + j * p_Nq + i;

          const dfloat G00 = ggeo[gbase + p_G00ID * p_Np];
          const dfloat G01 = ggeo[gbase + p_G01ID * p_Np];
          const dfloat G02 = ggeo[gbase + p_G02ID * p_Np];

          const dfloat G11 = ggeo[gbase + p_G11ID * p_Np];
          const dfloat G12 = ggeo[gbase + p_G12ID * p_Np];
          const dfloat G22 = ggeo[gbase + p_G22ID * p_Np];

          const dfloat GwJ = ggeo[gbase + p_GWJID * p_Np];

          s_GUr[j][i] = u_lam0 * (G00 * Ur + G01 * Us + G02 * r_Ut);
          s_GUs[j][i] = u_lam0 * (G01 * Ur + G11 * Us + G12 * r_Ut);
          r_Ut        = u_lam0 * (G02 * Ur + G12 * Us + G22 * r_Ut);

          s_GVr[j][i] = v_lam0 * (G00 * Vr + G01 * Vs + G02 * r_Vt);
          s_GVs[j][i] = v_lam0 * (G01 * Vr + G11 * Vs + G12 * r_Vt);
          r_Vt        = v_lam0 * (G02 * Vr + G12 * Vs + G22 * r_Vt);

          r_AU[k] += GwJ * u_lam1 * r_U[k];
          r_AV[k] += GwJ * v_lam1 * r_V[k];
        }
      }

      @barrier("local");

      for(int j = 0; j < p_Nq; ++j; @inner(1)) {
        for(int i = 0; i < p_Nq; ++i; @inner(0)) {
          dfloat AUtmp = 0, AVtmp = 0, AWtmp = 0;

#pragma unroll p_Nq
          for(int m = 0; m < p_Nq; m++) {
            // 9 shared, 18 flops => 12TB/s*18/(9*8) = 3TFLOPS/s
            dfloat Dmi = s_D[m][i];
            dfloat Dmj = s_D[m][j];
            dfloat Dkm = s_D[k][m];

            AUtmp += Dmi * s_GUr[j][m];
            AUtmp += Dmj * s_GUs[m][i];

            AVtmp += Dmi * s_GVr[j][m];
            AVtmp += Dmj * s_GVs[m][i];

            r_AU[m] += Dkm * r_Ut;
            r_AV[m] += Dkm * r_Vt;
          }
          r_AU[k] += AUtmp;
          r_AV[k] += AVtmp;
        }
      }
    }

    for(int j = 0; j < p_Nq; ++j; @inner(1)) {
      for(int i = 0; i < p_Nq; ++i; @inner(0)) {
#pragma unroll p_Nq
        for(int k = 0; k < p_Nq; k++) {
          const dlong id = e * p_Np + k * p_Nq * p_Nq + j * p_Nq + i;
          Aq[id + 0 * offset] = r_AU[k];
          Aq[id + 1 * offset] = r_AV[k];
        }
      }
    }
  }
}

// Currently Implemented for
@kernel void ellipticBlockAxVarHex3D_N3(const dlong Nelements,
                                        const dlong offset,
                                        const dlong loffset,
                                        @restrict const dlong* elementList,
                                        @restrict const dfloat* ggeo,
                                        @restrict const dfloat* D,
                                        @restrict const dfloat*  S,
                                        @restrict const dfloat* lambda,
                                        @restrict const dfloat* q,
                                        @restrict dfloat* Aq)
{
  for(dlong e = 0; e < Nelements; ++e; @outer(0)) {
    @shared dfloat s_D[p_Nq][p_Nq];

    @shared dfloat s_U[p_Nq][p_Nq];
    @shared dfloat s_V[p_Nq][p_Nq];
    @shared dfloat s_W[p_Nq][p_Nq];

    @shared dfloat s_GUr[p_Nq][p_Nq];
    @shared dfloat s_GUs[p_Nq][p_Nq];

    @shared dfloat s_GVr[p_Nq][p_Nq];
    @shared dfloat s_GVs[p_Nq][p_Nq];

    @shared dfloat s_GWr[p_Nq][p_Nq];
    @shared dfloat s_GWs[p_Nq][p_Nq];

    @exclusive dfloat r_Ut, r_Vt, r_Wt;

    // too much register ....(2*3*8 for N=7)
    @exclusive dfloat r_U[p_Nq], r_V[p_Nq],  r_W[p_Nq];
    @exclusive dfloat r_AU[p_Nq], r_AV[p_Nq], r_AW[p_Nq];

    // array of threads
    for(int j = 0; j < p_Nq; ++j; @inner(1))
      for(int i = 0; i < p_Nq; ++i; @inner(0)) {
        //load D into local memory
        // s_D[i][j] = d \phi_i at node j
        s_D[j][i] = D[p_Nq * j + i]; // D is column major

        // load pencil of u into register
        const dlong base = i + j * p_Nq + e * p_Np;

        for(int k = 0; k < p_Nq; k++) {
          //
          r_U[k] = q[base + k * p_Nq * p_Nq + 0 * offset];
          r_V[k] = q[base + k * p_Nq * p_Nq + 1 * offset];
          r_W[k] = q[base + k * p_Nq * p_Nq + 2 * offset];
          //
          r_AU[k] = 0.f;
          r_AV[k] = 0.f;
          r_AW[k] = 0.f;
        }
      }

    // Layer by layer
#pragma unroll p_Nq
    for(int k = 0; k < p_Nq; k++) {
      @barrier("local");

      for(int j = 0; j < p_Nq; ++j; @inner(1)) {
        for(int i = 0; i < p_Nq; ++i; @inner(0)) {
          // share u(:,:,k)
          s_U[j][i] = r_U[k];
          s_V[j][i] = r_V[k];
          s_W[j][i] = r_W[k];

          r_Ut = 0;
          r_Vt = 0;
          r_Wt = 0;

#pragma unroll p_Nq
          for(int m = 0; m < p_Nq; m++) {
            // 1 shared, 6 flops => 12*6/(1*8) = 9 TFLOPSs > peak
            dfloat Dkm = s_D[k][m];
            r_Ut += Dkm * r_U[m];
            r_Vt += Dkm * r_V[m];
            r_Wt += Dkm * r_W[m];
          }
        }
      }

      @barrier("local");

      for(int j = 0; j < p_Nq; ++j; @inner(1)) {
        for(int i = 0; i < p_Nq; ++i; @inner(0)) {
          dfloat Ur = 0.f, Us = 0.f;
          dfloat Vr = 0.f, Vs = 0.f;
          dfloat Wr = 0.f, Ws = 0.f;

#pragma unroll p_Nq
          for(int m = 0; m < p_Nq; m++) {
            // 8 shared, 12 FLOPS => 12TB/s*12/(8*8) => 2.25TF on V100
            dfloat Dim = s_D[i][m];
            dfloat Djm = s_D[j][m];

            Ur += Dim * s_U[j][m];
            Us += Djm * s_U[m][i];

            Vr += Dim * s_V[j][m];
            Vs += Djm * s_V[m][i];

            Wr += Dim * s_W[j][m];
            Ws += Djm * s_W[m][i];
          }

          const dlong id = e * p_Np + k * p_Nq * p_Nq + j * p_Nq + i;
          const dfloat u_lam0 = lambda[id + 0 * offset + 0 * loffset];
          const dfloat u_lam1 = lambda[id + 1 * offset + 0 * loffset];
          const dfloat v_lam0 = lambda[id + 0 * offset + 1 * loffset];
          const dfloat v_lam1 = lambda[id + 1 * offset + 1 * loffset];
          const dfloat w_lam0 = lambda[id + 0 * offset + 2 * loffset];
          const dfloat w_lam1 = lambda[id + 1 * offset + 2 * loffset];

          const dlong gbase = e * p_Nggeo * p_Np + k * p_Nq * p_Nq + j * p_Nq + i;
          const dfloat G00 = ggeo[gbase + p_G00ID * p_Np];
          const dfloat G01 = ggeo[gbase + p_G01ID * p_Np];
          const dfloat G02 = ggeo[gbase + p_G02ID * p_Np];
          const dfloat G11 = ggeo[gbase + p_G11ID * p_Np];
          const dfloat G12 = ggeo[gbase + p_G12ID * p_Np];
          const dfloat G22 = ggeo[gbase + p_G22ID * p_Np];
          const dfloat GwJ = ggeo[gbase + p_GWJID * p_Np];

          s_GUr[j][i] = u_lam0 * (G00 * Ur + G01 * Us + G02 * r_Ut);
          s_GUs[j][i] = u_lam0 * (G01 * Ur + G11 * Us + G12 * r_Ut);
          r_Ut        = u_lam0 * (G02 * Ur + G12 * Us + G22 * r_Ut);

          s_GVr[j][i] = v_lam0 * (G00 * Vr + G01 * Vs + G02 * r_Vt);
          s_GVs[j][i] = v_lam0 * (G01 * Vr + G11 * Vs + G12 * r_Vt);
          r_Vt        = v_lam0 * (G02 * Vr + G12 * Vs + G22 * r_Vt);

          s_GWr[j][i] = w_lam0 * (G00 * Wr + G01 * Ws + G02 * r_Wt);
          s_GWs[j][i] = w_lam0 * (G01 * Wr + G11 * Ws + G12 * r_Wt);
          r_Wt        = w_lam0 * (G02 * Wr + G12 * Ws + G22 * r_Wt);

          r_AU[k] += GwJ * u_lam1 * r_U[k];
          r_AV[k] += GwJ * v_lam1 * r_V[k];
          r_AW[k] += GwJ * w_lam1 * r_W[k];
        }
      }

      @barrier("local");

      for(int j = 0; j < p_Nq; ++j; @inner(1)) {
        for(int i = 0; i < p_Nq; ++i; @inner(0)) {
          dfloat AUtmp = 0, AVtmp = 0, AWtmp = 0;

#pragma unroll p_Nq
          for(int m = 0; m < p_Nq; m++) {
            // 9 shared, 18 flops => 12TB/s*18/(9*8) = 3TFLOPS/s
            dfloat Dmi = s_D[m][i];
            dfloat Dmj = s_D[m][j];
            dfloat Dkm = s_D[k][m];

            AUtmp += Dmi * s_GUr[j][m];
            AUtmp += Dmj * s_GUs[m][i];

            AVtmp += Dmi * s_GVr[j][m];
            AVtmp += Dmj * s_GVs[m][i];

            AWtmp += Dmi * s_GWr[j][m];
            AWtmp += Dmj * s_GWs[m][i];

            r_AU[m] += Dkm * r_Ut;
            r_AV[m] += Dkm * r_Vt;
            r_AW[m] += Dkm * r_Wt;
          }

          r_AU[k] += AUtmp;
          r_AV[k] += AVtmp;
          r_AW[k] += AWtmp;
        }
      }
    }

    // write out

    for(int j = 0; j < p_Nq; ++j; @inner(1)) {
      for(int i = 0; i < p_Nq; ++i; @inner(0)) {
#pragma unroll p_Nq
        for(int k = 0; k < p_Nq; k++) {
          const dlong id = e * p_Np + k * p_Nq * p_Nq + j * p_Nq + i;
          Aq[id + 0 * offset] = r_AU[k];
          Aq[id + 1 * offset] = r_AV[k];
          Aq[id + 2 * offset] = r_AW[k];
        }
      }
    }
  }
}

// Currently Implemented for
@kernel void ellipticBlockPartialAxVarHex3D_N1(const dlong Nelements,
                                               const dlong offset,
                                               const dlong loffset,
                                               @restrict const dlong* elementList,
                                               @restrict const dfloat* ggeo,
                                               @restrict const dfloat* D,
                                               @restrict const dfloat*  S,
                                               @restrict const dfloat* lambda,
                                               @restrict const dfloat* q,
                                               @restrict dfloat* Aq)
{
  for(dlong e = 0; e < Nelements; ++e; @outer(0)) {
    @shared dfloat s_D[p_Nq][p_Nq];

    @shared dfloat s_U[p_Nq][p_Nq];
    @shared dfloat s_GUr[p_Nq][p_Nq];
    @shared dfloat s_GUs[p_Nq][p_Nq];

    @exclusive dlong element;

    @exclusive dfloat r_Ut;
    @exclusive dfloat r_U[p_Nq], r_AU[p_Nq];
    // array of threads
    for(int j = 0; j < p_Nq; ++j; @inner(1))
      for(int i = 0; i < p_Nq; ++i; @inner(0)) {
        element = elementList[e];
        //load D into local memory
        // s_D[i][j] = d \phi_i at node j
        s_D[j][i] = D[p_Nq * j + i]; // D is column major
        // load pencil of u into register
        const dlong base = i + j * p_Nq + element * p_Np;

        for(int k = 0; k < p_Nq; k++) {
          r_U[k] = q[base + k * p_Nq * p_Nq + 0 * offset];
          //zero out
          r_AU[k] = 0.f;
        }
      }

    // Layer by layer
#pragma unroll p_Nq
    for(int k = 0; k < p_Nq; k++) {
      @barrier("local");

      for(int j = 0; j < p_Nq; ++j; @inner(1)) {
        for(int i = 0; i < p_Nq; ++i; @inner(0)) {
          s_U[j][i] = r_U[k];
          r_Ut = 0;

#pragma unroll p_Nq
          for(int m = 0; m < p_Nq; m++) {
            dfloat Dkm = s_D[k][m];
            r_Ut += Dkm * r_U[m];
          }
        }
      }

      @barrier("local");

      for(int j = 0; j < p_Nq; ++j; @inner(1)) {
        for(int i = 0; i < p_Nq; ++i; @inner(0)) {
          dfloat Ur = 0.f, Us = 0.f;
#pragma unroll p_Nq
          for(int m = 0; m < p_Nq; m++) {
            // 8 shared, 12 FLOPS => 12TB/s*12/(8*8) => 2.25TF on V100
            dfloat Dim = s_D[i][m];
            dfloat Djm = s_D[j][m];

            Ur += Dim * s_U[j][m];
            Us += Djm * s_U[m][i];
          }

          const dlong id = element * p_Np + k * p_Nq * p_Nq + j * p_Nq + i;
          const dfloat u_lam0 = lambda[id + 0 * offset + 0 * loffset];
          const dfloat u_lam1 = lambda[id + 1 * offset + 0 * loffset];

          const dlong gbase = element * p_Nggeo * p_Np + k * p_Nq * p_Nq + j * p_Nq + i;
          const dfloat G00 = ggeo[gbase + p_G00ID * p_Np];
          const dfloat G01 = ggeo[gbase + p_G01ID * p_Np];
          const dfloat G02 = ggeo[gbase + p_G02ID * p_Np];
          const dfloat G11 = ggeo[gbase + p_G11ID * p_Np];
          const dfloat G12 = ggeo[gbase + p_G12ID * p_Np];
          const dfloat G22 = ggeo[gbase + p_G22ID * p_Np];
          const dfloat GwJ = ggeo[gbase + p_GWJID * p_Np];

          s_GUr[j][i] = u_lam0 * (G00 * Ur + G01 * Us + G02 * r_Ut);
          s_GUs[j][i] = u_lam0 * (G01 * Ur + G11 * Us + G12 * r_Ut);
          r_Ut        = u_lam0 * (G02 * Ur + G12 * Us + G22 * r_Ut);
          r_AU[k]    += GwJ * u_lam1 * r_U[k];
        }
      }

      @barrier("local");

      for(int j = 0; j < p_Nq; ++j; @inner(1)) {
        for(int i = 0; i < p_Nq; ++i; @inner(0)) {
          dfloat AUtmp = 0;

#pragma unroll p_Nq
          for(int m = 0; m < p_Nq; m++) {
            AUtmp   += s_D[m][i] * s_GUr[j][m];
            AUtmp   += s_D[m][j] * s_GUs[m][i];
            r_AU[m] += s_D[k][m] * r_Ut;
          }
          r_AU[k] += AUtmp;
        }
      }
    }

    // write out

    for(int j = 0; j < p_Nq; ++j; @inner(1)) {
      for(int i = 0; i < p_Nq; ++i; @inner(0)) {
#pragma unroll p_Nq
        for(int k = 0; k < p_Nq; k++) {
          const dlong id = element * p_Np + k * p_Nq * p_Nq + j * p_Nq + i;
          Aq[id + 0 * offset] = r_AU[k];
        }
      }
    }
  }
}

// Currently Implemented for
@kernel void ellipticBlockPartialAxVarHex3D_N2(const dlong Nelements,
                                               const dlong offset,
                                               const dlong loffset,
                                               @restrict const dlong* elementList,
                                               @restrict const dfloat* ggeo,
                                               @restrict const dfloat* D,
                                               @restrict const dfloat*  S,
                                               @restrict const dfloat* lambda,
                                               @restrict const dfloat* q,
                                               @restrict dfloat* Aq)
{
  for(dlong e = 0; e < Nelements; ++e; @outer(0)) {
    @shared dfloat s_D[p_Nq][p_Nq];

    @shared dfloat s_U[p_Nq][p_Nq];
    @shared dfloat s_V[p_Nq][p_Nq];
    @shared dfloat s_W[p_Nq][p_Nq];

    @shared dfloat s_GUr[p_Nq][p_Nq];
    @shared dfloat s_GUs[p_Nq][p_Nq];
    @shared dfloat s_GVr[p_Nq][p_Nq];
    @shared dfloat s_GVs[p_Nq][p_Nq];

    @exclusive dlong element;

    @exclusive dfloat r_Ut, r_Vt, r_Wt;

    // too much register ....(2*3*8 for N=7)
    @exclusive dfloat r_U[p_Nq], r_V[p_Nq];
    @exclusive dfloat r_AU[p_Nq], r_AV[p_Nq];

    // array of threads
    for(int j = 0; j < p_Nq; ++j; @inner(1))
      for(int i = 0; i < p_Nq; ++i; @inner(0)) {
        element = elementList[e];
        //load D into local memory
        // s_D[i][j] = d \phi_i at node j
        s_D[j][i] = D[p_Nq * j + i]; // D is column major

        // load pencil of u into register
        const dlong base = i + j * p_Nq + element * p_Np;

        for(int k = 0; k < p_Nq; k++) {
          //
          r_U[k] = q[base + k * p_Nq * p_Nq + 0 * offset];
          r_V[k] = q[base + k * p_Nq * p_Nq + 1 * offset];
          //
          r_AU[k] = 0.f;
          r_AV[k] = 0.f;
        }
      }

    // Layer by layer
#pragma unroll p_Nq
    for(int k = 0; k < p_Nq; k++) {
      @barrier("local");

      for(int j = 0; j < p_Nq; ++j; @inner(1)) {
        for(int i = 0; i < p_Nq; ++i; @inner(0)) {
          // share u(:,:,k)
          s_U[j][i] = r_U[k];
          s_V[j][i] = r_V[k];

          r_Ut = 0;
          r_Vt = 0;

#pragma unroll p_Nq
          for(int m = 0; m < p_Nq; m++) {
            // 1 shared, 6 flops => 12*6/(1*8) = 9 TFLOPSs > peak
            dfloat Dkm = s_D[k][m];
            r_Ut += Dkm * r_U[m];
            r_Vt += Dkm * r_V[m];
          }
        }
      }

      @barrier("local");

      for(int j = 0; j < p_Nq; ++j; @inner(1)) {
        for(int i = 0; i < p_Nq; ++i; @inner(0)) {
          dfloat Ur = 0.f, Us = 0.f;
          dfloat Vr = 0.f, Vs = 0.f;

#pragma unroll p_Nq
          for(int m = 0; m < p_Nq; m++) {
            // 8 shared, 12 FLOPS => 12TB/s*12/(8*8) => 2.25TF on V100
            dfloat Dim = s_D[i][m];
            dfloat Djm = s_D[j][m];

            Ur += Dim * s_U[j][m];
            Us += Djm * s_U[m][i];

            Vr += Dim * s_V[j][m];
            Vs += Djm * s_V[m][i];
          }
          const dlong id = element * p_Np + k * p_Nq * p_Nq + j * p_Nq + i;
          const dfloat u_lam0 = lambda[id + 0 * offset + 0 * loffset];
          const dfloat u_lam1 = lambda[id + 1 * offset + 0 * loffset];
          const dfloat v_lam0 = lambda[id + 0 * offset + 1 * loffset];
          const dfloat v_lam1 = lambda[id + 1 * offset + 1 * loffset];

          const dlong gbase = element * p_Nggeo * p_Np + k * p_Nq * p_Nq + j * p_Nq + i;
          const dfloat G00 = ggeo[gbase + p_G00ID * p_Np];
          const dfloat G01 = ggeo[gbase + p_G01ID * p_Np];
          const dfloat G02 = ggeo[gbase + p_G02ID * p_Np];
          const dfloat G11 = ggeo[gbase + p_G11ID * p_Np];
          const dfloat G12 = ggeo[gbase + p_G12ID * p_Np];
          const dfloat G22 = ggeo[gbase + p_G22ID * p_Np];
          const dfloat GwJ = ggeo[gbase + p_GWJID * p_Np];

          s_GUr[j][i] = u_lam0 * (G00 * Ur + G01 * Us + G02 * r_Ut);
          s_GUs[j][i] = u_lam0 * (G01 * Ur + G11 * Us + G12 * r_Ut);
          r_Ut        = u_lam0 * (G02 * Ur + G12 * Us + G22 * r_Ut);

          s_GVr[j][i] = v_lam0 * (G00 * Vr + G01 * Vs + G02 * r_Vt);
          s_GVs[j][i] = v_lam0 * (G01 * Vr + G11 * Vs + G12 * r_Vt);
          r_Vt        = v_lam0 * (G02 * Vr + G12 * Vs + G22 * r_Vt);

          r_AU[k] += GwJ * u_lam1 * r_U[k];
          r_AV[k] += GwJ * v_lam1 * r_V[k];
        }
      }

      @barrier("local");

      for(int j = 0; j < p_Nq; ++j; @inner(1)) {
        for(int i = 0; i < p_Nq; ++i; @inner(0)) {
          dfloat AUtmp = 0, AVtmp = 0, AWtmp = 0;

#pragma unroll p_Nq
          for(int m = 0; m < p_Nq; m++) {
            // 9 shared, 18 flops => 12TB/s*18/(9*8) = 3TFLOPS/s
            dfloat Dmi = s_D[m][i];
            dfloat Dmj = s_D[m][j];
            dfloat Dkm = s_D[k][m];

            AUtmp += Dmi * s_GUr[j][m];
            AUtmp += Dmj * s_GUs[m][i];

            AVtmp += Dmi * s_GVr[j][m];
            AVtmp += Dmj * s_GVs[m][i];

            r_AU[m] += Dkm * r_Ut;
            r_AV[m] += Dkm * r_Vt;
          }
          r_AU[k] += AUtmp;
          r_AV[k] += AVtmp;
        }
      }
    }

    for(int j = 0; j < p_Nq; ++j; @inner(1)) {
      for(int i = 0; i < p_Nq; ++i; @inner(0)) {
#pragma unroll p_Nq
        for(int k = 0; k < p_Nq; k++) {
          const dlong id = element * p_Np + k * p_Nq * p_Nq + j * p_Nq + i;
          Aq[id + 0 * offset] = r_AU[k];
          Aq[id + 1 * offset] = r_AV[k];
        }
      }
    }
  }
}

// Currently Implemented for
@kernel void ellipticBlockPartialAxVarHex3D_N3(const dlong Nelements,
                                               const dlong offset,
                                               const dlong loffset,
                                               @restrict const dlong* elementList,
                                               @restrict const dfloat* ggeo,
                                               @restrict const dfloat* D,
                                               @restrict const dfloat*  S,
                                               @restrict const dfloat* lambda,
                                               @restrict const dfloat* q,
                                               @restrict dfloat* Aq)
{
  for(dlong e = 0; e < Nelements; ++e; @outer(0)) {
    @shared dfloat s_D[p_Nq][p_Nq];

    @shared dfloat s_U[p_Nq][p_Nq];
    @shared dfloat s_V[p_Nq][p_Nq];
    @shared dfloat s_W[p_Nq][p_Nq];

    @shared dfloat s_GUr[p_Nq][p_Nq];
    @shared dfloat s_GUs[p_Nq][p_Nq];

    @shared dfloat s_GVr[p_Nq][p_Nq];
    @shared dfloat s_GVs[p_Nq][p_Nq];

    @shared dfloat s_GWr[p_Nq][p_Nq];
    @shared dfloat s_GWs[p_Nq][p_Nq];

    @exclusive dfloat r_Ut, r_Vt, r_Wt;

    @exclusive dlong element;
    // too much register ....(2*3*8 for N=7)
    @exclusive dfloat r_U[p_Nq], r_V[p_Nq],  r_W[p_Nq];
    @exclusive dfloat r_AU[p_Nq], r_AV[p_Nq], r_AW[p_Nq];

    // array of threads
    for(int j = 0; j < p_Nq; ++j; @inner(1))
      for(int i = 0; i < p_Nq; ++i; @inner(0)) {
        element = elementList[e];
        //load D into local memory
        // s_D[i][j] = d \phi_i at node j
        s_D[j][i] = D[p_Nq * j + i]; // D is column major

        // load pencil of u into register
        const dlong base = i + j * p_Nq + element * p_Np;

        for(int k = 0; k < p_Nq; k++) {
          //
          r_U[k] = q[base + k * p_Nq * p_Nq + 0 * offset];
          r_V[k] = q[base + k * p_Nq * p_Nq + 1 * offset];
          r_W[k] = q[base + k * p_Nq * p_Nq + 2 * offset];
          //
          r_AU[k] = 0.f;
          r_AV[k] = 0.f;
          r_AW[k] = 0.f;
        }
      }

    // Layer by layer
#pragma unroll p_Nq
    for(int k = 0; k < p_Nq; k++) {
      @barrier("local");

      for(int j = 0; j < p_Nq; ++j; @inner(1)) {
        for(int i = 0; i < p_Nq; ++i; @inner(0)) {
          // share u(:,:,k)
          s_U[j][i] = r_U[k];
          s_V[j][i] = r_V[k];
          s_W[j][i] = r_W[k];

          r_Ut = 0;
          r_Vt = 0;
          r_Wt = 0;

#pragma unroll p_Nq
          for(int m = 0; m < p_Nq; m++) {
            // 1 shared, 6 flops => 12*6/(1*8) = 9 TFLOPSs > peak
            dfloat Dkm = s_D[k][m];
            r_Ut += Dkm * r_U[m];
            r_Vt += Dkm * r_V[m];
            r_Wt += Dkm * r_W[m];
          }
        }
      }

      @barrier("local");

      for(int j = 0; j < p_Nq; ++j; @inner(1)) {
        for(int i = 0; i < p_Nq; ++i; @inner(0)) {
          dfloat Ur = 0.f, Us = 0.f;
          dfloat Vr = 0.f, Vs = 0.f;
          dfloat Wr = 0.f, Ws = 0.f;

#pragma unroll p_Nq
          for(int m = 0; m < p_Nq; m++) {
            // 8 shared, 12 FLOPS => 12TB/s*12/(8*8) => 2.25TF on V100
            dfloat Dim = s_D[i][m];
            dfloat Djm = s_D[j][m];
            Ur += Dim * s_U[j][m];
            Us += Djm * s_U[m][i];
            Vr += Dim * s_V[j][m];
            Vs += Djm * s_V[m][i];
            Wr += Dim * s_W[j][m];
            Ws += Djm * s_W[m][i];
          }
          const dlong id = element * p_Np + k * p_Nq * p_Nq + j * p_Nq + i;
          const dfloat u_lam0 = lambda[id + 0 * offset + 0 * loffset];
          const dfloat u_lam1 = lambda[id + 1 * offset + 0 * loffset];
          const dfloat v_lam0 = lambda[id + 0 * offset + 1 * loffset];
          const dfloat v_lam1 = lambda[id + 1 * offset + 1 * loffset];
          const dfloat w_lam0 = lambda[id + 0 * offset + 2 * loffset];
          const dfloat w_lam1 = lambda[id + 1 * offset + 2 * loffset];

          const dlong gbase = element * p_Nggeo * p_Np + k * p_Nq * p_Nq + j * p_Nq + i;
          const dfloat G00 = ggeo[gbase + p_G00ID * p_Np];
          const dfloat G01 = ggeo[gbase + p_G01ID * p_Np];
          const dfloat G02 = ggeo[gbase + p_G02ID * p_Np];
          const dfloat G11 = ggeo[gbase + p_G11ID * p_Np];
          const dfloat G12 = ggeo[gbase + p_G12ID * p_Np];
          const dfloat G22 = ggeo[gbase + p_G22ID * p_Np];
          const dfloat GwJ = ggeo[gbase + p_GWJID * p_Np];

          s_GUr[j][i] = u_lam0 * (G00 * Ur + G01 * Us + G02 * r_Ut);
          s_GUs[j][i] = u_lam0 * (G01 * Ur + G11 * Us + G12 * r_Ut);
          r_Ut        = u_lam0 * (G02 * Ur + G12 * Us + G22 * r_Ut);
          //
          s_GVr[j][i] = v_lam0 * (G00 * Vr + G01 * Vs + G02 * r_Vt);
          s_GVs[j][i] = v_lam0 * (G01 * Vr + G11 * Vs + G12 * r_Vt);
          r_Vt        = v_lam0 * (G02 * Vr + G12 * Vs + G22 * r_Vt);
          //
          s_GWr[j][i] = w_lam0 * (G00 * Wr + G01 * Ws + G02 * r_Wt);
          s_GWs[j][i] = w_lam0 * (G01 * Wr + G11 * Ws + G12 * r_Wt);
          r_Wt        = w_lam0 * (G02 * Wr + G12 * Ws + G22 * r_Wt);
          //
          r_AU[k] += GwJ * u_lam1 * r_U[k];
          r_AV[k] += GwJ * v_lam1 * r_V[k];
          r_AW[k] += GwJ * w_lam1 * r_W[k];
        }
      }

      @barrier("local");

      for(int j = 0; j < p_Nq; ++j; @inner(1)) {
        for(int i = 0; i < p_Nq; ++i; @inner(0)) {
          dfloat AUtmp = 0, AVtmp = 0, AWtmp = 0;

#pragma unroll p_Nq
          for(int m = 0; m < p_Nq; m++) {
            // 9 shared, 18 flops => 12TB/s*18/(9*8) = 3TFLOPS/s
            dfloat Dmi = s_D[m][i];
            dfloat Dmj = s_D[m][j];
            dfloat Dkm = s_D[k][m];

            AUtmp += Dmi * s_GUr[j][m];
            AUtmp += Dmj * s_GUs[m][i];

            AVtmp += Dmi * s_GVr[j][m];
            AVtmp += Dmj * s_GVs[m][i];

            AWtmp += Dmi * s_GWr[j][m];
            AWtmp += Dmj * s_GWs[m][i];

            r_AU[m] += Dkm * r_Ut;
            r_AV[m] += Dkm * r_Vt;
            r_AW[m] += Dkm * r_Wt;
          }

          r_AU[k] += AUtmp;
          r_AV[k] += AVtmp;
          r_AW[k] += AWtmp;
        }
      }
    }

    // write out

    for(int j = 0; j < p_Nq; ++j; @inner(1)) {
      for(int i = 0; i < p_Nq; ++i; @inner(0)) {
#pragma unroll p_Nq
        for(int k = 0; k < p_Nq; k++) {
          const dlong id = element * p_Np + k * p_Nq * p_Nq + j * p_Nq + i;
          Aq[id + 0 * offset] = r_AU[k];
          Aq[id + 1 * offset] = r_AV[k];
          Aq[id + 2 * offset] = r_AW[k];
        }
      }
    }
  }
}

@kernel void ellipticStressAxVarHex3D(const dlong Nelements,
                                      const dlong offset,
                                      const dlong loffset,
                                      @restrict const dfloat* vgeo,
                                      @restrict const dfloat* D,
                                      @restrict const dfloat*  S,
                                      @restrict const dfloat* lambda,
                                      @restrict const dfloat* q,
                                      @restrict dfloat* Aq)
{
  for(dlong e = 0; e < Nelements; ++e; @outer(0)) {
    // AK: heavy memory usage, optimize later
    @shared dfloat s_D[p_Nq][p_Nq];

    @shared dfloat s_U[p_Nq][p_Nq];
    @shared dfloat s_V[p_Nq][p_Nq];
    @shared dfloat s_W[p_Nq][p_Nq];
    @shared dfloat s_SUr[p_Nq][p_Nq];
    @shared dfloat s_SUs[p_Nq][p_Nq];

    @exclusive dfloat s_Uloc[p_Nq];
    @exclusive dfloat s_Vloc[p_Nq];
    @exclusive dfloat s_Wloc[p_Nq];

    @exclusive dfloat s_SUtloc[p_Nq];

    @shared dfloat s_SVr[p_Nq][p_Nq];
    @shared dfloat s_SVs[p_Nq][p_Nq];
    @exclusive dfloat s_SVt[p_Nq];

    @shared dfloat s_SWr[p_Nq][p_Nq];
    @shared dfloat s_SWs[p_Nq][p_Nq];
    @exclusive dfloat s_SWt[p_Nq];
    //
    @exclusive dfloat rx, ry, rz;
    @exclusive dfloat sx, sy, sz;
    @exclusive dfloat tx, ty, tz;

    // Symmetric Stress Tensor
    @exclusive dfloat s11,s12,s13;
    @exclusive dfloat s21,s22,s23;
    @exclusive dfloat s31,s32,s33;

    @exclusive dfloat r_Au[p_Nq];
    @exclusive dfloat r_Av[p_Nq];
    @exclusive dfloat r_Aw[p_Nq];

    // prefetch q
    for(int k = 0; k < p_Nq; ++k) {
      for(int j = 0; j < p_Nq; ++j; @inner(1))
        for(int i = 0; i < p_Nq; ++i; @inner(0)) {
          if(k == 0) s_D[j][i] = D[p_Nq * j + i];
          const dlong id = e * p_Np + k * p_Nq * p_Nq + j * p_Nq + i;
          s_U[j][i] = q[id + 0 * offset];
          s_V[j][i] = q[id + 1 * offset];
          s_W[j][i] = q[id + 2 * offset];
          if(k == 0) {
            for(int l = 0; l < p_Nq; ++l) {
              const dlong other_id = e * p_Np + l * p_Nq * p_Nq + j * p_Nq + i;
              s_Uloc[l] = q[other_id + 0 * offset];
              s_Vloc[l] = q[other_id + 1 * offset];
              s_Wloc[l] = q[other_id + 2 * offset];
            }
          }
        }
      @barrier("local");
      for(int j = 0; j < p_Nq; ++j; @inner(1))
        for(int i = 0; i < p_Nq; ++i; @inner(0)) {
          const dlong gid = i + j * p_Nq + k * p_Nq * p_Nq + e * p_Np * p_Nvgeo;
          rx = vgeo[gid + p_RXID * p_Np];
          ry = vgeo[gid + p_RYID * p_Np];
          rz = vgeo[gid + p_RZID * p_Np];

          sx = vgeo[gid + p_SXID * p_Np];
          sy = vgeo[gid + p_SYID * p_Np];
          sz = vgeo[gid + p_SZID * p_Np];

          tx = vgeo[gid + p_TXID * p_Np];
          ty = vgeo[gid + p_TYID * p_Np];
          tz = vgeo[gid + p_TZID * p_Np];

          const dfloat JW = vgeo[gid + p_JWID * p_Np];

          // compute 1D derivatives
          dfloat ur = 0.f, us = 0.f, ut = 0.f;
          dfloat vr = 0.f, vs = 0.f, vt = 0.f;
          dfloat wr = 0.f, ws = 0.f, wt = 0.f;
          for(int m = 0; m < p_Nq; ++m) {
            const dfloat Dim = s_D[i][m]; // Dr
            const dfloat Djm = s_D[j][m]; // Ds
            const dfloat Dkm = s_D[k][m]; // Dt

            ur += Dim * s_U[j][m];
            us += Djm * s_U[m][i];
            ut += Dkm * s_Uloc[m];
            //
            vr += Dim * s_V[j][m];
            vs += Djm * s_V[m][i];
            vt += Dkm * s_Vloc[m];
            //
            wr += Dim * s_W[j][m];
            ws += Djm * s_W[m][i];
            wt += Dkm * s_Wloc[m];
          }

          const dlong id = e * p_Np + k * p_Nq * p_Nq + j * p_Nq + i;
          // not sure that we need anistropic diffusion!!!!
          // con be simplified for istropic diffusion
          const dfloat u_lam0 = lambda[id + 0 * offset + 0 * loffset];
          const dfloat u_lam1 = lambda[id + 1 * offset + 0 * loffset];
          const dfloat v_lam0 = lambda[id + 0 * offset + 1 * loffset];
          const dfloat v_lam1 = lambda[id + 1 * offset + 1 * loffset];
          const dfloat w_lam0 = lambda[id + 0 * offset + 2 * loffset];
          const dfloat w_lam1 = lambda[id + 1 * offset + 2 * loffset];

          const dfloat dudx = rx * ur + sx * us + tx * ut;
          const dfloat dudy = ry * ur + sy * us + ty * ut;
          const dfloat dudz = rz * ur + sz * us + tz * ut;

          const dfloat dvdx = rx * vr + sx * vs + tx * vt;
          const dfloat dvdy = ry * vr + sy * vs + ty * vt;
          const dfloat dvdz = rz * vr + sz * vs + tz * vt;

          const dfloat dwdx = rx * wr + sx * ws + tx * wt;
          const dfloat dwdy = ry * wr + sy * ws + ty * wt;
          const dfloat dwdz = rz * wr + sz * ws + tz * wt;

          s11 = u_lam0 * JW * (dudx + dudx);
          s12 = u_lam0 * JW * (dudy + dvdx);
          s13 = u_lam0 * JW * (dudz + dwdx);

          s21 = v_lam0 * JW * (dvdx + dudy);
          s22 = v_lam0 * JW * (dvdy + dvdy);
          s23 = v_lam0 * JW * (dvdz + dwdy);

          s31 = w_lam0 * JW * (dwdx + dudz);
          s32 = w_lam0 * JW * (dwdy + dvdz);
          s33 = w_lam0 * JW * (dwdz + dwdz);
          // store in register
          r_Au[k] =  u_lam1 * JW * s_U[j][i];
          r_Av[k] =  v_lam1 * JW * s_V[j][i];
          r_Aw[k] =  w_lam1 * JW * s_W[j][i];
        }
      @barrier("local");
      for(int j = 0; j < p_Nq; ++j; @inner(1))
        for(int i = 0; i < p_Nq; ++i; @inner(0)) {
          s_SUr[j][i] =  rx * s11 + ry * s12 + rz * s13;
          s_SUs[j][i] =  sx * s11 + sy * s12 + sz * s13;
          s_SUtloc[k] =  tx * s11 + ty * s12 + tz * s13;
          //
          s_SVr[j][i] =  rx * s21 + ry * s22 + rz * s23;
          s_SVs[j][i] =  sx * s21 + sy * s22 + sz * s23;
          s_SVt[k] =  tx * s21 + ty * s22 + tz * s23;
          //
          s_SWr[j][i] =  rx * s31 + ry * s32 + rz * s33;
          s_SWs[j][i] =  sx * s31 + sy * s32 + sz * s33;
          s_SWt[k] =  tx * s31 + ty * s32 + tz * s33;
        }
      @barrier("local");
      for(int j = 0; j < p_Nq; ++j; @inner(1)) {
        for(int i = 0; i < p_Nq; ++i; @inner(0)) {
#pragma unroll p_Nq
          for(int m = 0; m < p_Nq; m++) {
            const dfloat Dim = s_D[m][i]; // Dr'
            const dfloat Djm = s_D[m][j]; // Ds'

            r_Au[k] += Dim * s_SUr[j][m];
            r_Au[k] += Djm * s_SUs[m][i];

            r_Av[k] += Dim * s_SVr[j][m];
            r_Av[k] += Djm * s_SVs[m][i];

            r_Aw[k] += Dim * s_SWr[j][m];
            r_Aw[k] += Djm * s_SWs[m][i];
          }
        }
      }
      @barrier("local");
    }

    for(int k = 0; k < p_Nq; ++k) {
      for(int j = 0; j < p_Nq; ++j; @inner(1)) {
        for(int i = 0; i < p_Nq; ++i; @inner(0)) {
#pragma unroll p_Nq
          for(int m = 0; m < p_Nq; m++) {
            const dfloat Dkm = s_D[m][k]; // Dt'

            r_Au[k] += Dkm * s_SUtloc[m];

            r_Av[k] += Dkm * s_SVt[m];

            r_Aw[k] += Dkm * s_SWt[m];
          }
          const dlong id = e * p_Np + k * p_Nq * p_Nq + j * p_Nq + i;
          Aq[id + 0 * offset] = r_Au[k];
          Aq[id + 1 * offset] = r_Av[k];
          Aq[id + 2 * offset] = r_Aw[k];
        }
      }
    }
  }
}

//
@kernel void ellipticStressPartialAxVarHex3D(const dlong Nelements,
                                             const dlong offset,
                                             const dlong loffset,
                                             @restrict const dlong* elementList,
                                             @restrict const dfloat* vgeo,
                                             @restrict const dfloat* D,
                                             @restrict const dfloat*  S,
                                             @restrict const dfloat* lambda,
                                             @restrict const dfloat* q,
                                             @restrict dfloat* Aq)
{
  for(dlong e = 0; e < Nelements; ++e; @outer(0)) {
    @shared dfloat s_D[p_Nq][p_Nq];

    @shared dfloat s_U[p_Nq][p_Nq];
    @shared dfloat s_V[p_Nq][p_Nq];
    @shared dfloat s_W[p_Nq][p_Nq];
    @exclusive dfloat s_Uloc[p_Nq];
    @exclusive dfloat s_Vloc[p_Nq];
    @exclusive dfloat s_Wloc[p_Nq];
    @shared dfloat s_SUr[p_Nq][p_Nq];
    @shared dfloat s_SUs[p_Nq][p_Nq];
    @exclusive dfloat s_SUtloc[p_Nq];

    @shared dfloat s_SVr[p_Nq][p_Nq];
    @shared dfloat s_SVs[p_Nq][p_Nq];
    @exclusive dfloat s_SVt[p_Nq];

    @shared dfloat s_SWr[p_Nq][p_Nq];
    @shared dfloat s_SWs[p_Nq][p_Nq];
    @exclusive dfloat s_SWt[p_Nq];

    //
    @exclusive dfloat rx, ry, rz;
    @exclusive dfloat sx, sy, sz;
    @exclusive dfloat tx, ty, tz;
    // Symmetric Stress Tensor
    @exclusive dfloat s11,s12,s13;
    @exclusive dfloat s21,s22,s23;
    @exclusive dfloat s31,s32,s33;

    @exclusive dfloat r_Au[p_Nq];
    @exclusive dfloat r_Av[p_Nq];
    @exclusive dfloat r_Aw[p_Nq];
    @exclusive dlong element;

    // prefetch q
    for(int k = 0; k < p_Nq; ++k) {
      for(int j = 0; j < p_Nq; ++j; @inner(1))
        for(int i = 0; i < p_Nq; ++i; @inner(0)) {
          element = elementList[e];
          if(k == 0) s_D[j][i] = D[p_Nq * j + i];
          const dlong id = element * p_Np + k * p_Nq * p_Nq + j * p_Nq + i;
          s_U[j][i] = q[id + 0 * offset];
          s_V[j][i] = q[id + 1 * offset];
          s_W[j][i] = q[id + 2 * offset];
          if(k == 0) {
            for(int l = 0; l < p_Nq; ++l) {
              const dlong other_id = element * p_Np + l * p_Nq * p_Nq + j * p_Nq + i;
              s_Uloc[l] = q[other_id + 0 * offset];
              s_Vloc[l] = q[other_id + 1 * offset];
              s_Wloc[l] = q[other_id + 2 * offset];
            }
          }
        }
      @barrier("local");
      for(int j = 0; j < p_Nq; ++j; @inner(1))
        for(int i = 0; i < p_Nq; ++i; @inner(0)) {
          const dlong gid = i + j * p_Nq + k * p_Nq * p_Nq + element * p_Np * p_Nvgeo;
          rx = vgeo[gid + p_RXID * p_Np];
          ry = vgeo[gid + p_RYID * p_Np];
          rz = vgeo[gid + p_RZID * p_Np];

          sx = vgeo[gid + p_SXID * p_Np];
          sy = vgeo[gid + p_SYID * p_Np];
          sz = vgeo[gid + p_SZID * p_Np];

          tx = vgeo[gid + p_TXID * p_Np];
          ty = vgeo[gid + p_TYID * p_Np];
          tz = vgeo[gid + p_TZID * p_Np];

          const dfloat JW = vgeo[gid + p_JWID * p_Np];

          // compute 1D derivatives
          dfloat ur = 0.f, us = 0.f, ut = 0.f;
          dfloat vr = 0.f, vs = 0.f, vt = 0.f;
          dfloat wr = 0.f, ws = 0.f, wt = 0.f;
          for(int m = 0; m < p_Nq; ++m) {
            const dfloat Dim = s_D[i][m]; // Dr
            const dfloat Djm = s_D[j][m]; // Ds
            const dfloat Dkm = s_D[k][m]; // Dt

            ur += Dim * s_U[j][m];
            us += Djm * s_U[m][i];
            ut += Dkm * s_Uloc[m];
            //
            vr += Dim * s_V[j][m];
            vs += Djm * s_V[m][i];
            vt += Dkm * s_Vloc[m];
            //
            wr += Dim * s_W[j][m];
            ws += Djm * s_W[m][i];
            wt += Dkm * s_Wloc[m];
          }

          const dlong id = element * p_Np + k * p_Nq * p_Nq + j * p_Nq + i;

          const dfloat u_lam0 = lambda[id + 0 * offset + 0 * loffset];
          const dfloat u_lam1 = lambda[id + 1 * offset + 0 * loffset];
          const dfloat v_lam0 = lambda[id + 0 * offset + 1 * loffset];
          const dfloat v_lam1 = lambda[id + 1 * offset + 1 * loffset];
          const dfloat w_lam0 = lambda[id + 0 * offset + 2 * loffset];
          const dfloat w_lam1 = lambda[id + 1 * offset + 2 * loffset];

          const dfloat dudx = rx * ur + sx * us + tx * ut;
          const dfloat dudy = ry * ur + sy * us + ty * ut;
          const dfloat dudz = rz * ur + sz * us + tz * ut;

          const dfloat dvdx = rx * vr + sx * vs + tx * vt;
          const dfloat dvdy = ry * vr + sy * vs + ty * vt;
          const dfloat dvdz = rz * vr + sz * vs + tz * vt;

          const dfloat dwdx = rx * wr + sx * ws + tx * wt;
          const dfloat dwdy = ry * wr + sy * ws + ty * wt;
          const dfloat dwdz = rz * wr + sz * ws + tz * wt;

          s11 = u_lam0 * JW * (dudx + dudx);
          s12 = u_lam0 * JW * (dudy + dvdx);
          s13 = u_lam0 * JW * (dudz + dwdx);

          s21 = v_lam0 * JW * (dvdx + dudy);
          s22 = v_lam0 * JW * (dvdy + dvdy);
          s23 = v_lam0 * JW * (dvdz + dwdy);

          s31 = w_lam0 * JW * (dwdx + dudz);
          s32 = w_lam0 * JW * (dwdy + dvdz);
          s33 = w_lam0 * JW * (dwdz + dwdz);
          // store in register
          r_Au[k] =  u_lam1 * JW * s_U[j][i];
          r_Av[k] =  v_lam1 * JW * s_V[j][i];
          r_Aw[k] =  w_lam1 * JW * s_W[j][i];
        }
      @barrier("local");
      for(int j = 0; j < p_Nq; ++j; @inner(1))
        for(int i = 0; i < p_Nq; ++i; @inner(0)) {
          s_SUr[j][i] =  rx * s11 + ry * s12 + rz * s13;
          s_SUs[j][i] =  sx * s11 + sy * s12 + sz * s13;
          s_SUtloc[k] =  tx * s11 + ty * s12 + tz * s13;
          //
          s_SVr[j][i] =  rx * s21 + ry * s22 + rz * s23;
          s_SVs[j][i] =  sx * s21 + sy * s22 + sz * s23;
          s_SVt[k] =  tx * s21 + ty * s22 + tz * s23;
          //
          s_SWr[j][i] =  rx * s31 + ry * s32 + rz * s33;
          s_SWs[j][i] =  sx * s31 + sy * s32 + sz * s33;
          s_SWt[k] =  tx * s31 + ty * s32 + tz * s33;
        }
      @barrier("local");
      for(int j = 0; j < p_Nq; ++j; @inner(1)) {
        for(int i = 0; i < p_Nq; ++i; @inner(0)) {
#pragma unroll p_Nq
          for(int m = 0; m < p_Nq; m++) {
            const dfloat Dim = s_D[m][i]; // Dr'
            const dfloat Djm = s_D[m][j]; // Ds'

            r_Au[k] += Dim * s_SUr[j][m];
            r_Au[k] += Djm * s_SUs[m][i];

            r_Av[k] += Dim * s_SVr[j][m];
            r_Av[k] += Djm * s_SVs[m][i];

            r_Aw[k] += Dim * s_SWr[j][m];
            r_Aw[k] += Djm * s_SWs[m][i];
          }
        }
      }
    }

// loop over slabs
    for(int k = 0; k < p_Nq; ++k) {
      for(int j = 0; j < p_Nq; ++j; @inner(1)) {
        for(int i = 0; i < p_Nq; ++i; @inner(0)) {
#pragma unroll p_Nq
          for(int m = 0; m < p_Nq; m++) {
            const dfloat Dkm = s_D[m][k]; // Dt'

            r_Au[k] += Dkm * s_SUtloc[m];

            r_Av[k] += Dkm * s_SVt[m];

            r_Aw[k] += Dkm * s_SWt[m];
          }
          const dlong id = element * p_Np + k * p_Nq * p_Nq + j * p_Nq + i;
          Aq[id + 0 * offset] = r_Au[k];
          Aq[id + 1 * offset] = r_Av[k];
          Aq[id + 2 * offset] = r_Aw[k];
        }
      }
    }
  }
}

//
@kernel void ellipticStressAxHex3D(const dlong Nelements,
                                   const dlong offset,
                                   const dlong loffset,
                                   @restrict const dfloat* vgeo,
                                   @restrict const dfloat* D,
                                   @restrict const dfloat*  S,
                                   @restrict const dfloat* lambda,
                                   @restrict const dfloat* q,
                                   @restrict dfloat* Aq)
{
  for(dlong e = 0; e < Nelements; ++e; @outer(0)) {
    // AK: heavy memory usage, optimize later
    @shared dfloat s_D[p_Nq][p_Nq];

    @shared dfloat s_U[p_Nq][p_Nq];
    @shared dfloat s_V[p_Nq][p_Nq];
    @shared dfloat s_W[p_Nq][p_Nq];
    @shared dfloat s_SUr[p_Nq][p_Nq];
    @shared dfloat s_SUs[p_Nq][p_Nq];
    @exclusive dfloat s_Uloc[p_Nq];
    @exclusive dfloat s_Vloc[p_Nq];
    @exclusive dfloat s_Wloc[p_Nq];
    @exclusive dfloat s_SUtloc[p_Nq];

    @shared dfloat s_SVr[p_Nq][p_Nq];
    @shared dfloat s_SVs[p_Nq][p_Nq];
    @exclusive dfloat s_SVt[p_Nq];

    @shared dfloat s_SWr[p_Nq][p_Nq];
    @shared dfloat s_SWs[p_Nq][p_Nq];
    @exclusive dfloat s_SWt[p_Nq];
    //
    @exclusive dfloat rx, ry, rz;
    @exclusive dfloat sx, sy, sz;
    @exclusive dfloat tx, ty, tz;

    // Symmetric Stress Tensor
    @exclusive dfloat s11,s12,s13;
    @exclusive dfloat s21,s22,s23;
    @exclusive dfloat s31,s32,s33;

    @exclusive dfloat r_Au[p_Nq];
    @exclusive dfloat r_Av[p_Nq];
    @exclusive dfloat r_Aw[p_Nq];

    // prefetch q
    for(int k = 0; k < p_Nq; ++k) {
      for(int j = 0; j < p_Nq; ++j; @inner(1))
        for(int i = 0; i < p_Nq; ++i; @inner(0)) {
          if(k == 0) s_D[j][i] = D[p_Nq * j + i];
          const dlong id = e * p_Np + k * p_Nq * p_Nq + j * p_Nq + i;
          s_U[j][i] = q[id + 0 * offset];
          s_V[j][i] = q[id + 1 * offset];
          s_W[j][i] = q[id + 2 * offset];
          if(k == 0) {
            for(int l = 0; l < p_Nq; ++l) {
              const dlong other_id = e * p_Np + l * p_Nq * p_Nq + j * p_Nq + i;
              s_Uloc[l] = q[other_id + 0 * offset];
              s_Vloc[l] = q[other_id + 1 * offset];
              s_Wloc[l] = q[other_id + 2 * offset];
            }
          }
        }
      @barrier("local");
      for(int j = 0; j < p_Nq; ++j; @inner(1))
        for(int i = 0; i < p_Nq; ++i; @inner(0)) {
          const dlong gid = i + j * p_Nq + k * p_Nq * p_Nq + e * p_Np * p_Nvgeo;
          rx = vgeo[gid + p_RXID * p_Np];
          ry = vgeo[gid + p_RYID * p_Np];
          rz = vgeo[gid + p_RZID * p_Np];

          sx = vgeo[gid + p_SXID * p_Np];
          sy = vgeo[gid + p_SYID * p_Np];
          sz = vgeo[gid + p_SZID * p_Np];

          tx = vgeo[gid + p_TXID * p_Np];
          ty = vgeo[gid + p_TYID * p_Np];
          tz = vgeo[gid + p_TZID * p_Np];

          const dfloat JW = vgeo[gid + p_JWID * p_Np];

          // compute 1D derivatives
          dfloat ur = 0.f, us = 0.f, ut = 0.f;
          dfloat vr = 0.f, vs = 0.f, vt = 0.f;
          dfloat wr = 0.f, ws = 0.f, wt = 0.f;
          for(int m = 0; m < p_Nq; ++m) {
            const dfloat Dim = s_D[i][m]; // Dr
            const dfloat Djm = s_D[j][m]; // Ds
            const dfloat Dkm = s_D[k][m]; // Dt

            ur += Dim * s_U[j][m];
            us += Djm * s_U[m][i];
            ut += Dkm * s_Uloc[m];
            //
            vr += Dim * s_V[j][m];
            vs += Djm * s_V[m][i];
            vt += Dkm * s_Vloc[m];
            //
            wr += Dim * s_W[j][m];
            ws += Djm * s_W[m][i];
            wt += Dkm * s_Wloc[m];
          }

          const dlong id = e * p_Np + k * p_Nq * p_Nq + j * p_Nq + i;

          const dfloat dudx = rx * ur + sx * us + tx * ut;
          const dfloat dudy = ry * ur + sy * us + ty * ut;
          const dfloat dudz = rz * ur + sz * us + tz * ut;

          const dfloat dvdx = rx * vr + sx * vs + tx * vt;
          const dfloat dvdy = ry * vr + sy * vs + ty * vt;
          const dfloat dvdz = rz * vr + sz * vs + tz * vt;

          const dfloat dwdx = rx * wr + sx * ws + tx * wt;
          const dfloat dwdy = ry * wr + sy * ws + ty * wt;
          const dfloat dwdz = rz * wr + sz * ws + tz * wt;

          s11 = JW * (dudx + dudx);
          s12 = JW * (dudy + dvdx);
          s13 = JW * (dudz + dwdx);

          s21 = JW * (dvdx + dudy);
          s22 = JW * (dvdy + dvdy);
          s23 = JW * (dvdz + dwdy);

          s31 = JW * (dwdx + dudz);
          s32 = JW * (dwdy + dvdz);
          s33 = JW * (dwdz + dwdz);
          // store in register
          r_Au[k] =  lambda[id + 1 * offset + 0 * loffset] * JW * s_U[j][i];
          r_Av[k] =  lambda[id + 1 * offset + 1 * loffset] * JW * s_V[j][i];
          r_Aw[k] =  lambda[id + 1 * offset + 2 * loffset] * JW * s_W[j][i];
        }
      @barrier("local");
      for(int j = 0; j < p_Nq; ++j; @inner(1))
        for(int i = 0; i < p_Nq; ++i; @inner(0)) {
          s_SUr[j][i] =  rx * s11 + ry * s12 + rz * s13;
          s_SUs[j][i] =  sx * s11 + sy * s12 + sz * s13;
          s_SUtloc[k] =  tx * s11 + ty * s12 + tz * s13;
          //
          s_SVr[j][i] =  rx * s21 + ry * s22 + rz * s23;
          s_SVs[j][i] =  sx * s21 + sy * s22 + sz * s23;
          s_SVt[k] =  tx * s21 + ty * s22 + tz * s23;
          //
          s_SWr[j][i] =  rx * s31 + ry * s32 + rz * s33;
          s_SWs[j][i] =  sx * s31 + sy * s32 + sz * s33;
          s_SWt[k] =  tx * s31 + ty * s32 + tz * s33;
        }
      @barrier("local");
      for(int j = 0; j < p_Nq; ++j; @inner(1)) {
        for(int i = 0; i < p_Nq; ++i; @inner(0)) {
#pragma unroll p_Nq
          for(int m = 0; m < p_Nq; m++) {
            const dfloat Dim = s_D[m][i]; // Dr'
            const dfloat Djm = s_D[m][j]; // Ds'

            r_Au[k] += Dim * s_SUr[j][m];
            r_Au[k] += Djm * s_SUs[m][i];

            r_Av[k] += Dim * s_SVr[j][m];
            r_Av[k] += Djm * s_SVs[m][i];

            r_Aw[k] += Dim * s_SWr[j][m];
            r_Aw[k] += Djm * s_SWs[m][i];
          }
        }
      }
    }

    for(int k = 0; k < p_Nq; ++k) {
      for(int j = 0; j < p_Nq; ++j; @inner(1)) {
        for(int i = 0; i < p_Nq; ++i; @inner(0)) {
#pragma unroll p_Nq
          for(int m = 0; m < p_Nq; m++) {
            const dfloat Dkm = s_D[m][k]; // Dt'

            r_Au[k] += Dkm * s_SUtloc[m];

            r_Av[k] += Dkm * s_SVt[m];

            r_Aw[k] += Dkm * s_SWt[m];
          }
          const dlong id = e * p_Np + k * p_Nq * p_Nq + j * p_Nq + i;
          Aq[id + 0 * offset] = r_Au[k];
          Aq[id + 1 * offset] = r_Av[k];
          Aq[id + 2 * offset] = r_Aw[k];
        }
      }
    }
  }
}

//
@kernel void ellipticStressPartialAxHex3D(const dlong Nelements,
                                          const dlong offset,
                                          const dlong loffset,
                                          @restrict const dlong* elementList,
                                          @restrict const dfloat* vgeo,
                                          @restrict const dfloat* D,
                                          @restrict const dfloat*  S,
                                          @restrict const dfloat* lambda,
                                          @restrict const dfloat* q,
                                          @restrict dfloat* Aq)
{
  for(dlong e = 0; e < Nelements; ++e; @outer(0)) {
    @shared dfloat s_D[p_Nq][p_Nq];

    @shared dfloat s_U[p_Nq][p_Nq];
    @shared dfloat s_V[p_Nq][p_Nq];
    @shared dfloat s_W[p_Nq][p_Nq];
    @shared dfloat s_SUr[p_Nq][p_Nq];
    @shared dfloat s_SUs[p_Nq][p_Nq];
    @exclusive dfloat s_Uloc[p_Nq];
    @exclusive dfloat s_Vloc[p_Nq];
    @exclusive dfloat s_Wloc[p_Nq];
    @exclusive dfloat s_SUtloc[p_Nq];

    @shared dfloat s_SVr[p_Nq][p_Nq];
    @shared dfloat s_SVs[p_Nq][p_Nq];
    @exclusive dfloat s_SVt[p_Nq];

    @shared dfloat s_SWr[p_Nq][p_Nq];
    @shared dfloat s_SWs[p_Nq][p_Nq];
    @exclusive dfloat s_SWt[p_Nq];

    //
    @exclusive dfloat rx, ry, rz;
    @exclusive dfloat sx, sy, sz;
    @exclusive dfloat tx, ty, tz;
    // Symmetric Stress Tensor
    @exclusive dfloat s11,s12,s13;
    @exclusive dfloat s21,s22,s23;
    @exclusive dfloat s31,s32,s33;

    @exclusive dfloat r_Au[p_Nq];
    @exclusive dfloat r_Av[p_Nq];
    @exclusive dfloat r_Aw[p_Nq];
    @exclusive dlong element;

    // prefetch q
    for(int k = 0; k < p_Nq; ++k) {
      for(int j = 0; j < p_Nq; ++j; @inner(1))
        for(int i = 0; i < p_Nq; ++i; @inner(0)) {
          element = elementList[e];
          if(k == 0) s_D[j][i] = D[p_Nq * j + i];
          const dlong id = element * p_Np + k * p_Nq * p_Nq + j * p_Nq + i;
          s_U[j][i] = q[id + 0 * offset];
          s_V[j][i] = q[id + 1 * offset];
          s_W[j][i] = q[id + 2 * offset];
          if(k == 0) {
            for(int l = 0; l < p_Nq; ++l) {
              const dlong other_id = element * p_Np + l * p_Nq * p_Nq + j * p_Nq + i;
              s_Uloc[l] = q[other_id + 0 * offset];
              s_Vloc[l] = q[other_id + 1 * offset];
              s_Wloc[l] = q[other_id + 2 * offset];
            }
          }
        }
      @barrier("local");
      for(int j = 0; j < p_Nq; ++j; @inner(1))
        for(int i = 0; i < p_Nq; ++i; @inner(0)) {
          const dlong gid = i + j * p_Nq + k * p_Nq * p_Nq + element * p_Np * p_Nvgeo;
          rx = vgeo[gid + p_RXID * p_Np];
          ry = vgeo[gid + p_RYID * p_Np];
          rz = vgeo[gid + p_RZID * p_Np];

          sx = vgeo[gid + p_SXID * p_Np];
          sy = vgeo[gid + p_SYID * p_Np];
          sz = vgeo[gid + p_SZID * p_Np];

          tx = vgeo[gid + p_TXID * p_Np];
          ty = vgeo[gid + p_TYID * p_Np];
          tz = vgeo[gid + p_TZID * p_Np];

          const dfloat JW = vgeo[gid + p_JWID * p_Np];

          // compute 1D derivatives
          dfloat ur = 0.f, us = 0.f, ut = 0.f;
          dfloat vr = 0.f, vs = 0.f, vt = 0.f;
          dfloat wr = 0.f, ws = 0.f, wt = 0.f;
          for(int m = 0; m < p_Nq; ++m) {
            const dfloat Dim = s_D[i][m]; // Dr
            const dfloat Djm = s_D[j][m]; // Ds
            const dfloat Dkm = s_D[k][m]; // Dt

            ur += Dim * s_U[j][m];
            us += Djm * s_U[m][i];
            ut += Dkm * s_Uloc[m];
            //
            vr += Dim * s_V[j][m];
            vs += Djm * s_V[m][i];
            vt += Dkm * s_Vloc[m];
            //
            wr += Dim * s_W[j][m];
            ws += Djm * s_W[m][i];
            wt += Dkm * s_Wloc[m];
          }

          const dfloat dudx = rx * ur + sx * us + tx * ut;
          const dfloat dudy = ry * ur + sy * us + ty * ut;
          const dfloat dudz = rz * ur + sz * us + tz * ut;

          const dfloat dvdx = rx * vr + sx * vs + tx * vt;
          const dfloat dvdy = ry * vr + sy * vs + ty * vt;
          const dfloat dvdz = rz * vr + sz * vs + tz * vt;

          const dfloat dwdx = rx * wr + sx * ws + tx * wt;
          const dfloat dwdy = ry * wr + sy * ws + ty * wt;
          const dfloat dwdz = rz * wr + sz * ws + tz * wt;

          s11 = JW * (dudx + dudx);
          s12 = JW * (dudy + dvdx);
          s13 = JW * (dudz + dwdx);

          s21 = JW * (dvdx + dudy);
          s22 = JW * (dvdy + dvdy);
          s23 = JW * (dvdz + dwdy);

          s31 = JW * (dwdx + dudz);
          s32 = JW * (dwdy + dvdz);
          s33 = JW * (dwdz + dwdz);
          const dlong id = e * p_Np + k * p_Nq * p_Nq + j * p_Nq + i;

          r_Au[k] =  lambda[id + 1 * offset + 0 * loffset] * JW * s_U[j][i];
          r_Av[k] =  lambda[id + 1 * offset + 1 * loffset] * JW * s_V[j][i];
          r_Aw[k] =  lambda[id + 1 * offset + 2 * loffset] * JW * s_W[j][i];
        }
      @barrier("local");
      for(int j = 0; j < p_Nq; ++j; @inner(1))
        for(int i = 0; i < p_Nq; ++i; @inner(0)) {
          s_SUr[j][i] =  rx * s11 + ry * s12 + rz * s13;
          s_SUs[j][i] =  sx * s11 + sy * s12 + sz * s13;
          s_SUtloc[k] =  tx * s11 + ty * s12 + tz * s13;
          //
          s_SVr[j][i] =  rx * s21 + ry * s22 + rz * s23;
          s_SVs[j][i] =  sx * s21 + sy * s22 + sz * s23;
          s_SVt[k] =  tx * s21 + ty * s22 + tz * s23;
          //
          s_SWr[j][i] =  rx * s31 + ry * s32 + rz * s33;
          s_SWs[j][i] =  sx * s31 + sy * s32 + sz * s33;
          s_SWt[k] =  tx * s31 + ty * s32 + tz * s33;
        }
      @barrier("local");
      for(int j = 0; j < p_Nq; ++j; @inner(1)) {
        for(int i = 0; i < p_Nq; ++i; @inner(0)) {
#pragma unroll p_Nq
          for(int m = 0; m < p_Nq; m++) {
            const dfloat Dim = s_D[m][i]; // Dr'
            const dfloat Djm = s_D[m][j]; // Ds'

            r_Au[k] += Dim * s_SUr[j][m];
            r_Au[k] += Djm * s_SUs[m][i];

            r_Av[k] += Dim * s_SVr[j][m];
            r_Av[k] += Djm * s_SVs[m][i];

            r_Aw[k] += Dim * s_SWr[j][m];
            r_Aw[k] += Djm * s_SWs[m][i];
          }
        }
      }
    }
    for(int k = 0; k < p_Nq; ++k) {
      for(int j = 0; j < p_Nq; ++j; @inner(1)) {
        for(int i = 0; i < p_Nq; ++i; @inner(0)) {
#pragma unroll p_Nq
          for(int m = 0; m < p_Nq; m++) {
            const dfloat Dkm = s_D[m][k]; // Dt'

            r_Au[k] += Dkm * s_SUtloc[m];

            r_Av[k] += Dkm * s_SVt[m];

            r_Aw[k] += Dkm * s_SWt[m];
          }
          const dlong id = element * p_Np + k * p_Nq * p_Nq + j * p_Nq + i;
          Aq[id + 0 * offset] = r_Au[k];
          Aq[id + 1 * offset] = r_Av[k];
          Aq[id + 2 * offset] = r_Aw[k];
        }
      }
    }
  }
}
